{"id":"el-07f","title":"Implement Extension Loading (load_extension)","description":"Add support for loading SQLite extensions (FTS5, R-Tree, JSON1, custom extensions).\n\n**Context**: SQLite extensions provide powerful features like full-text search (FTS5), spatial indexing (R-Tree), and enhanced JSON support. Currently not supported in ecto_libsql.\n\n**Missing NIFs** (from FEATURE_CHECKLIST.md):\n- load_extension_enable()\n- load_extension_disable()\n- load_extension(path)\n\n**Use Cases**:\n\n**1. Full-Text Search (FTS5)**:\n```elixir\nEctoLibSql.load_extension(repo, \"fts5\")\nRepo.query(\"CREATE VIRTUAL TABLE docs USING fts5(content)\")\nRepo.query(\"SELECT * FROM docs WHERE docs MATCH 'search terms'\")\n```\n\n**2. Spatial Indexing (R-Tree)**:\n```elixir\nEctoLibSql.load_extension(repo, \"rtree\")\nRepo.query(\"CREATE VIRTUAL TABLE spatial_idx USING rtree(id, minX, maxX, minY, maxY)\")\n```\n\n**3. Custom Extensions**:\n```elixir\nEctoLibSql.load_extension(repo, \"/path/to/custom.so\")\n```\n\n**Security Considerations**:\n- Extension loading is a security risk (arbitrary code execution)\n- Should be disabled by default\n- Require explicit opt-in via config\n- Validate extension paths\n- Consider allowlist of safe extensions\n\n**Implementation Required**:\n\n1. **Add NIFs** (native/ecto_libsql/src/connection.rs):\n   ```rust\n   #[rustler::nif]\n   fn load_extension_enable(conn_id: \u0026str) -\u003e NifResult\u003cAtom\u003e\n   \n   #[rustler::nif]\n   fn load_extension_disable(conn_id: \u0026str) -\u003e NifResult\u003cAtom\u003e\n   \n   #[rustler::nif]\n   fn load_extension(conn_id: \u0026str, path: \u0026str) -\u003e NifResult\u003cAtom\u003e\n   ```\n\n2. **Add safety wrappers** (lib/ecto_libsql/native.ex):\n   - Validate extension paths\n   - Check if loading is enabled\n   - Handle errors gracefully\n\n3. **Add config option** (lib/ecto/adapters/libsql.ex):\n   ```elixir\n   config :my_app, MyApp.Repo,\n     adapter: Ecto.Adapters.LibSql,\n     database: \"app.db\",\n     allow_extension_loading: true,  # Default: false\n     allowed_extensions: [\"fts5\", \"rtree\"]  # Optional allowlist\n   ```\n\n4. **Documentation**:\n   - Security warnings\n   - Extension loading guide\n   - FTS5 integration example\n   - Custom extension development guide\n\n**Files**:\n- native/ecto_libsql/src/connection.rs (NIFs)\n- lib/ecto_libsql/native.ex (wrappers)\n- lib/ecto/adapters/libsql.ex (config handling)\n- test/extension_test.exs (new tests)\n- AGENTS.md (update API docs)\n\n**Acceptance Criteria**:\n- [ ] load_extension_enable() NIF implemented\n- [ ] load_extension_disable() NIF implemented\n- [ ] load_extension(path) NIF implemented\n- [ ] Config option to control extension loading\n- [ ] Path validation for security\n- [ ] FTS5 example in documentation\n- [ ] Comprehensive tests including security tests\n- [ ] Clear security warnings in docs\n\n**Test Requirements**:\n```elixir\ntest \"load_extension fails when not enabled\" do\n  assert {:error, _} = EctoLibSql.load_extension(repo, \"fts5\")\nend\n\ntest \"load_extension works after enable\" do\n  :ok = EctoLibSql.load_extension_enable(repo)\n  :ok = EctoLibSql.load_extension(repo, \"fts5\")\n  # Verify FTS5 works\nend\n\ntest \"load_extension rejects absolute paths when restricted\" do\n  assert {:error, _} = EctoLibSql.load_extension(repo, \"/etc/passwd\")\nend\n```\n\n**References**:\n- FEATURE_CHECKLIST.md section \"Medium Priority\" item 4\n- LIBSQL_FEATURE_MATRIX_FINAL.md section 10\n\n**Priority**: P2 - Nice to have, enables advanced features\n**Effort**: 2-3 days\n**Security Review**: Required before implementation","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:44:08.997945+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","original_type":"feature"}
{"id":"el-092","title":"Clarify purpose of stmt_caching_benchmark_test.exs","description":"stmt_caching_benchmark_test.exs is ambiguous - unclear if it's a benchmark or a functional test:\n- File is in test/ directory (suggests functional test)\n- File name includes 'benchmark' (suggests it's a performance benchmark)\n- Content needs review to determine intent\n\nAction:\n1. Review the file contents\n2. If it's a benchmark: Move to bench/ directory with proper benchmarking setup\n3. If it's a functional test with assertions: Keep in test/, rename to stmt_caching_performance_test.exs or clarify the name\n\nEffort: 15 minutes\nImpact: Clarify test intent, proper test/benchmark infrastructure","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:55:32.47112+11:00","created_by":"drew","updated_at":"2026-01-08T12:57:34.387975+11:00","closed_at":"2026-01-08T12:57:34.387977+11:00"}
{"id":"el-0ez","title":"RANDOM ROWID Support (libSQL Extension)","description":"LibSQL-specific extension not in standard SQLite. CREATE TABLE ... RANDOM ROWID generates random rowid values instead of sequential. Useful for distributed systems. Cannot be combined with WITHOUT ROWID or AUTOINCREMENT.\n\nDesired API:\n  create table(:users, random_rowid: true) do\n    add :name, :string\n  end\n\nEffort: 1-2 days (simple DDL addition).","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-30T17:43:57.948488+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","original_type":"feature"}
{"id":"el-0mv","title":"Fix DateTime/Decimal parameter encoding for Oban compatibility","description":"**Problem**: PR #57 identified critical issues when using ecto_libsql with Oban:\n\n1. **DateTime encoding failure**: NIF cannot serialise DateTime/NaiveDateTime/Date/Time/Decimal structs, causing 'Unsupported argument type' errors\n2. **Oban Lifeline plugin failure**: 'protocol Enumerable not implemented for Atom. Got value: nil' when processing query results\n\n**Root Cause**: \n- Rustler cannot automatically serialise complex Elixir structs like DateTime\n- These need to be converted to ISO8601 strings before passing to the Rust NIF\n\n**Solution Implemented**:\n- Added encode/3 in lib/ecto_libsql/query.ex to convert temporal types and Decimal to strings\n- Added guard clause for non-list params to prevent crashes\n- Native.ex already correctly normalises result columns/rows (nil for write ops without RETURNING, lists otherwise)\n- Added comprehensive test suite for parameter encoding\n\n**Tests Added**:\n- test/ecto_libsql_query_encoding_test.exs - covers DateTime/Date/Time/Decimal encoding, nil/int/float/string/binary pass-through, mixed parameters\n\n**Note**: PR #57's proposed normalisation changes were incorrect - Ecto expects columns: nil, rows: nil for write operations WITHOUT RETURNING, not empty lists.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-12T22:07:32.62847+11:00","created_by":"Drew Robinson","updated_at":"2026-01-12T22:10:03.476502+11:00","closed_at":"2026-01-12T22:10:03.476502+11:00","close_reason":"Fix implemented and pushed to fix-pr57-issues branch. All tests pass (638 tests, 0 failures). Added comprehensive test coverage for parameter encoding."}
{"id":"el-0sr","title":"Better Collation Support","description":"Works via fragments. Locale-specific sorting, case-insensitive comparisons, Unicode handling. Desired API: field :name, :string, collation: :nocase in schema, order_by with COLLATE, add :name, :string, collation: \"BINARY\" in migration. Effort: 2 days.","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-30T17:35:53.286381+11:00","created_by":"drew","updated_at":"2025-12-30T17:36:47.512945+11:00"}
{"id":"el-0wo","title":"Test File","description":"test/cursor_streaming_test.exs (new file)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.006221+11:00","updated_at":"2026-01-12T11:58:25.498721+11:00","closed_at":"2026-01-12T11:58:25.498721+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-1fe","title":"Estimated Effort","description":"30 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.023278+11:00","updated_at":"2026-01-12T11:58:16.850549+11:00","closed_at":"2026-01-12T11:58:16.850549+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-1p2","title":"Document test layering strategy","description":"Create documentation clarifying what should be tested in Rust vs Elixir layers.\n\nFrom TEST_AUDIT_REPORT.md item 7: 'Document Test Layering Strategy' - helps contributors understand testing strategy.\n\n**Documentation to Create**:\n\n**Rust Tests** (native/ecto_libsql/src/tests/) - Low-level correctness\n- Parameter binding (types, NULL, BLOB)\n- Transaction semantics\n- Basic query execution\n- Error handling\n- libsql API integration\n\n**Elixir Tests** (test/) - Integration \u0026 compatibility\n- Ecto adapter callbacks\n- Schema validation\n- Migrations\n- Ecto queries (where, select, joins)\n- Associations, preloading\n- Connection pooling\n- Remote/replica behavior\n- Advanced features (vectors, R*Tree, JSON)\n\n**Decision Tree**: When adding tests, where should they go?\n\n**File**: TESTING.md (create or update)\n\n**Estimated Effort**: 1-2 hours\n\n**Impact**: Better contributor onboarding, clearer test intent","status":"open","priority":3,"issue_type":"task","estimated_minutes":80,"created_at":"2026-01-08T21:35:03.366397+11:00","created_by":"drew","updated_at":"2026-01-08T21:35:03.366397+11:00"}
{"id":"el-1xs","title":"Test Scenarios","description":"1. Savepoints in replica mode with sync","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.00987+11:00","updated_at":"2026-01-12T11:58:16.8798+11:00","closed_at":"2026-01-12T11:58:16.8798+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-1yl","title":"CTE (Common Table Expression) Support","description":"Ecto query builder generates CTEs, but ecto_libsql's connection module doesn't emit WITH clauses. Critical for complex queries and recursive data structures. Standard SQL feature widely used in other Ecto adapters. SQLite has supported CTEs since version 3.8.3 (2014). libSQL 3.45.1 fully supports CTEs with recursion.\n\nIMPLEMENTATION: Update lib/ecto/adapters/libsql/connection.ex:441 in the all/1 function to emit WITH clauses.\n\nPRIORITY: Recommended as #1 in implementation order - fills major gap, high user demand.\n\nEffort: 3-4 days.","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-30T17:35:51.064754+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Implemented CTE (WITH clause) support. Added SQL generation in connection.ex, Rust should_use_query() detection, and 9 comprehensive tests. Both simple and recursive CTEs work correctly.","original_type":"feature"}
{"id":"el-2ry","title":"Fix Prepared Statement Re-Preparation Performance Bug","description":"CRITICAL: Prepared statements are re-prepared on every execution, defeating their purpose and causing 30-50% performance overhead.\n\n**Problem**: query_prepared and execute_prepared re-prepare statements on every execution instead of reusing cached Statement objects.\n\n**Location**: \n- native/ecto_libsql/src/statement.rs lines 885-888\n- native/ecto_libsql/src/statement.rs lines 951-954\n\n**Current (Inefficient) Code**:\n```rust\n// PERFORMANCE BUG:\nlet stmt = conn_guard.prepare(\u0026sql).await  // ← Called EVERY time!\n```\n\n**Should Be**:\n```rust\n// Reuse prepared statement:\nlet stmt = get_from_registry(stmt_id)  // Reuse prepared statement\nstmt.reset()  // Clear bindings\nstmt.query(params).await\n```\n\n**Impact**:\n- ALL applications using prepared statements affected\n- 30-50% slower than optimal\n- Defeats Ecto's prepared statement caching\n- Production performance issue\n\n**Fix Required**:\n1. Store actual Statement objects in STMT_REGISTRY (not just SQL)\n2. Implement stmt.reset() to clear bindings\n3. Reuse Statement from registry in execute_prepared/query_prepared\n4. Add performance benchmark test\n\n**Files**:\n- native/ecto_libsql/src/statement.rs\n- native/ecto_libsql/src/constants.rs (STMT_REGISTRY structure)\n- test/performance_test.exs (add benchmark)\n\n**Acceptance Criteria**:\n- [ ] Statement objects stored in registry\n- [ ] reset() clears bindings without re-preparing\n- [ ] execute_prepared reuses cached Statement\n- [ ] query_prepared reuses cached Statement\n- [ ] Performance benchmark shows 30-50% improvement\n- [ ] All existing tests pass\n\n**References**:\n- LIBSQL_FEATURE_MATRIX_FINAL.md section 4\n- FEATURE_CHECKLIST.md Prepared Statement Methods\n\n**Priority**: P0 - Critical performance bug\n**Effort**: 3-4 days","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-30T17:43:14.213351+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Already fixed. Performance test shows 2.98x speedup. Statement objects are cached in STMT_REGISTRY and reused with reset() in query_prepared/execute_prepared.","original_type":"bug"}
{"id":"el-39j","title":"Impact","description":"Better contributor onboarding, clearer test intent","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.022214+11:00","updated_at":"2026-01-12T11:58:16.855046+11:00","closed_at":"2026-01-12T11:58:16.855046+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-3ea","title":"Better CHECK Constraint Support","description":"Basic support only. Data validation at database level, enforces invariants, complements Ecto changesets. Desired API: add :age, :integer, check: \"age \u003e= 0 AND age \u003c= 150\" or named constraints: create constraint(:users, :valid_age, check: \"age \u003e= 0\"). Effort: 2-3 days.","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-30T17:35:53.08432+11:00","created_by":"drew","updated_at":"2025-12-30T17:36:47.352126+11:00"}
{"id":"el-3m3","title":"/tmp/test_coverage_issues.md","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:33:39.08104+11:00","created_by":"drew","updated_at":"2026-01-12T11:58:25.508056+11:00","closed_at":"2026-01-12T11:58:25.508056+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-3pz","title":"Files to Check","description":"- ecto_libsql_test.exs (after cleanup)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.022938+11:00","updated_at":"2026-01-12T11:58:16.852181+11:00","closed_at":"2026-01-12T11:58:16.852181+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-4ha","title":"JSON Schema Helpers","description":"Works via fragments, but no dedicated support. libSQL 3.45.1 has JSON1 built into core (no longer optional). Functions: json_extract(), json_type(), json_array(), json_object(), json_each(), json_tree(). Operators: -\u003e and -\u003e\u003e (MySQL/PostgreSQL compatible). NEW: JSONB binary format support for 5-10% smaller storage and faster processing.\n\nDesired API:\n  from u in User, where: json_extract(u.settings, \"$.theme\") == \"dark\", select: {u.id, json_object(u.metadata)}\n\nPRIORITY: Recommended as #6 in implementation order.\n\nEffort: 4-5 days.","notes":"JSON helpers module (EctoLibSql.JSON) created with full API support - 54 comprehensive tests passing","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:51.917976+11:00","created_by":"drew","updated_at":"2026-01-05T14:53:34.773102+11:00","closed_at":"2026-01-05T14:53:34.773102+11:00","close_reason":"Closed"}
{"id":"el-4oc","title":"R*Tree Spatial Indexing Support","description":"Not implemented in ecto_libsql. libSQL 3.45.1 has full R*Tree extension in /ext/rtree/ directory. Complement to vector search for geospatial queries. Multi-dimensional range queries. Better than vector search for pure location data.\n\nUse cases: Geographic bounds queries, collision detection, time-range queries (2D: time + value).\n\nDesired API:\n  create table(:locations, rtree: true) do\n    add :min_lat, :float\n    add :max_lat, :float\n    add :min_lng, :float\n    add :max_lng, :float\n  end\n\n  from l in Location, where: rtree_intersects(l, ^bounds)\n\nEffort: 5-6 days.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-30T17:35:52.10625+11:00","created_by":"drew","updated_at":"2025-12-30T17:43:32.632868+11:00"}
{"id":"el-4tc","title":"Replace regex-based parameter extraction with SQL-aware parsing","description":"The current regex-based approach in extract_named_params/1 (lib/ecto_libsql.ex:298-303) cannot distinguish between parameter-like patterns in SQL string literals/comments and actual parameters.\n\nExample edge case:\n  SELECT ':not_a_param', name FROM users WHERE id = :actual_param\n\nThis would extract both \"not_a_param\" and \"actual_param\", even though the first is in a string literal.\n\nCurrent mitigations:\n1. SQL string literals with parameter-like patterns are uncommon\n2. Validation catches truly missing parameters\n3. Extra entries are ignored during binding\n\nPotential solutions:\n1. Use prepared statement introspection (like lib/ecto_libsql/native.ex)\n2. Implement a simple SQL parser that tracks quoted strings and comments\n3. Use a proper SQL parsing library (if one exists for Elixir/LibSQL)\n\nBenefits of fixing:\n- More robust parameter extraction\n- Handles edge cases correctly\n- Better alignment with execute path (which uses introspection)\n\nNote: This is only used in the query path (SELECT/EXPLAIN/WITH/RETURNING) where we bypass prepared statement introspection for performance. The execute path already uses the correct introspection approach.","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-07T11:59:35.264582+11:00","created_by":"drew","updated_at":"2026-01-07T11:59:35.264582+11:00"}
{"id":"el-53e","title":"Estimated Effort","description":"1-2 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.021875+11:00","updated_at":"2026-01-12T11:58:16.856458+11:00","closed_at":"2026-01-12T11:58:16.856458+11:00","close_reason":"Malformed fragment issue - not a valid task"}
{"id":"el-5ef","title":"Add Cross-Connection Security Tests","description":"Add comprehensive security tests to verify connections cannot access each other's resources.\n\n**Context**: ecto_libsql implements ownership tracking (TransactionEntry.conn_id, cursor ownership, statement ownership) but needs comprehensive tests to verify security boundaries.\n\n**Security Boundaries to Test**:\n\n**1. Transaction Isolation**:\n```elixir\ntest \"connection A cannot access connection B's transaction\" do\n  {:ok, conn_a} = connect(database: \"a.db\")\n  {:ok, conn_b} = connect(database: \"b.db\")\n  \n  {:ok, trx_id} = begin_transaction(conn_a)\n  \n  # Should fail - transaction belongs to conn_a\n  assert {:error, msg} = execute_with_transaction(conn_b, trx_id, \"SELECT 1\")\n  assert msg =~ \"does not belong to this connection\"\nend\n```\n\n**2. Statement Isolation**:\n```elixir\ntest \"connection A cannot access connection B's prepared statement\" do\n  {:ok, conn_a} = connect(database: \"a.db\")\n  {:ok, conn_b} = connect(database: \"b.db\")\n  \n  {:ok, stmt_id} = prepare_statement(conn_a, \"SELECT 1\")\n  \n  # Should fail - statement belongs to conn_a\n  assert {:error, msg} = execute_prepared(conn_b, stmt_id, [])\n  assert msg =~ \"Statement not found\" or msg =~ \"does not belong\"\nend\n```\n\n**3. Cursor Isolation**:\n```elixir\ntest \"connection A cannot access connection B's cursor\" do\n  {:ok, conn_a} = connect(database: \"a.db\")\n  {:ok, conn_b} = connect(database: \"b.db\")\n  \n  {:ok, cursor_id} = declare_cursor(conn_a, \"SELECT 1\")\n  \n  # Should fail - cursor belongs to conn_a\n  assert {:error, msg} = fetch_cursor(conn_b, cursor_id, 10)\n  assert msg =~ \"Cursor not found\" or msg =~ \"does not belong\"\nend\n```\n\n**4. Savepoint Isolation**:\n```elixir\ntest \"connection A cannot access connection B's savepoint\" do\n  {:ok, conn_a} = connect(database: \"a.db\")\n  {:ok, conn_b} = connect(database: \"b.db\")\n  \n  {:ok, trx_id} = begin_transaction(conn_a)\n  {:ok, _} = savepoint(conn_a, trx_id, \"sp1\")\n  \n  # Should fail - savepoint belongs to conn_a's transaction\n  assert {:error, msg} = rollback_to_savepoint(conn_b, trx_id, \"sp1\")\n  assert msg =~ \"does not belong to this connection\"\nend\n```\n\n**5. Concurrent Access Races**:\n```elixir\ntest \"concurrent cursor fetches are safe\" do\n  {:ok, conn} = connect()\n  {:ok, cursor_id} = declare_cursor(conn, \"SELECT * FROM large_table\")\n  \n  # Multiple processes try to fetch concurrently\n  tasks = for _ \u003c- 1..10 do\n    Task.async(fn -\u003e fetch_cursor(conn, cursor_id, 10) end)\n  end\n  \n  results = Task.await_many(tasks)\n  \n  # Should not crash, should handle gracefully\n  assert Enum.all?(results, fn r -\u003e match?({:ok, _}, r) or match?({:error, _}, r) end)\nend\n```\n\n**6. Process Crash Cleanup**:\n```elixir\ntest \"resources cleaned up when connection process crashes\" do\n  # Start connection in separate process\n  pid = spawn(fn -\u003e\n    {:ok, conn} = connect()\n    {:ok, trx_id} = begin_transaction(conn)\n    {:ok, cursor_id} = declare_cursor(conn, \"SELECT 1\")\n    \n    # Store IDs for verification\n    send(self(), {:ids, conn.conn_id, trx_id, cursor_id})\n    \n    # Wait to be killed\n    Process.sleep(:infinity)\n  end)\n  \n  receive do\n    {:ids, conn_id, trx_id, cursor_id} -\u003e\n      # Kill the process\n      Process.exit(pid, :kill)\n      Process.sleep(100)\n      \n      # Resources should be cleaned up (or marked orphaned)\n      # Verify they can't be accessed\n  end\nend\n```\n\n**7. Connection Pool Isolation**:\n```elixir\ntest \"pooled connections are isolated\" do\n  # Get two connections from pool\n  conn1 = get_pooled_connection()\n  conn2 = get_pooled_connection()\n  \n  # Each should have independent resources\n  {:ok, trx1} = begin_transaction(conn1)\n  {:ok, trx2} = begin_transaction(conn2)\n  \n  # Should not interfere\n  assert trx1 != trx2\n  \n  # Commit conn1, should not affect conn2\n  :ok = commit_transaction(conn1, trx1)\n  assert is_in_transaction?(conn2, trx2)\nend\n```\n\n**Implementation**:\n\n1. **Create test file** (test/security_test.exs):\n   - Transaction isolation tests\n   - Statement isolation tests\n   - Cursor isolation tests\n   - Savepoint isolation tests\n   - Concurrent access tests\n   - Cleanup tests\n   - Pool isolation tests\n\n2. **Add stress tests** for concurrent access patterns\n\n3. **Add fuzzing** for edge cases\n\n**Files**:\n- NEW: test/security_test.exs\n- Reference: FEATURE_CHECKLIST.md line 290-310\n- Reference: LIBSQL_FEATURE_COMPARISON.md section 4\n\n**Acceptance Criteria**:\n- [ ] Transaction isolation verified\n- [ ] Statement isolation verified\n- [ ] Cursor isolation verified\n- [ ] Savepoint isolation verified\n- [ ] Concurrent access safe\n- [ ] Resource cleanup verified\n- [ ] Pool isolation verified\n- [ ] All tests pass consistently\n- [ ] No race conditions detected\n\n**Security Guarantees**:\nAfter these tests pass, we can guarantee:\n- Connections cannot access each other's transactions\n- Connections cannot access each other's prepared statements\n- Connections cannot access each other's cursors\n- Savepoints are properly scoped to owning transaction\n- Concurrent access is thread-safe\n- Resources are cleaned up on connection close\n\n**References**:\n- LIBSQL_FEATURE_COMPARISON.md section \"Error Handling for Edge Cases\" line 290-310\n- Current implementation: TransactionEntry.conn_id ownership tracking\n\n**Priority**: P2 - Important for security guarantees\n**Effort**: 2 days","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T17:46:44.853925+11:00","created_by":"drew","updated_at":"2026-01-12T11:57:52.138183+11:00","closed_at":"2026-01-12T11:57:52.138183+11:00","close_reason":"Tests implemented in test/security_test.exs - covers transaction, statement, cursor, savepoint, concurrent access, and pool isolation","original_type":"task"}
{"id":"el-5mr","title":"Investigate and add comprehensive type encoding tests","description":"Add comprehensive tests in test/ecto_integration_test.exs for all type encodings: 1) UUID structs in query params, 2) Boolean values in raw queries, 3) Atom :null handling, 4) Nested structures (document expected failure), 5) Edge cases like empty strings, large numbers, special characters. Tests should verify both successful encoding and appropriate error messages for unsupported types.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:53:07.09718+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T14:46:48.377888+11:00","closed_at":"2026-01-13T14:46:48.377888+11:00","close_reason":"Closed"}
{"id":"el-5nw","title":"Add error handling tests to Rust NIF layer","description":"Current Rust tests (integration_tests.rs) focus on happy path. Need tests for error scenarios to verify the Rust layer returns errors instead of panicking.\n\nMissing tests:\n- Invalid connection ID → should return error (not panic)\n- Invalid statement ID → should return error (not panic)\n- Invalid transaction ID → should return error (not panic)\n- Invalid cursor ID → should return error (not panic)\n- Parameter count mismatch → should return error\n- Resource exhaustion scenarios\n\nThis is important for verifying that the Rust layer doesn't crash the BEAM VM on invalid inputs.\n\nLocation: native/ecto_libsql/src/tests/error_handling_tests.rs (new file)\n\nEffort: 1-2 hours\nImpact: Robustness, baseline for Elixir error tests, verifies no panic on invalid inputs","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:55:41.582902+11:00","created_by":"drew","updated_at":"2026-01-08T21:30:40.104531+11:00","closed_at":"2026-01-08T21:30:40.104531+11:00","close_reason":"Closed"}
{"id":"el-6r5","title":"Document SQLite/LibSQL Known Limitations in Skipped Tests","description":"Several tests are skipped due to inherent SQLite/LibSQL limitations (not missing features):\n\n## Skipped Tests\n\n### 1. ecto_sql_transaction_compat_test.exs:218,228\n**Tag**: `@tag :sqlite_concurrency_limitation`\n**Tests**: \n- 'rollback is per repository connection'\n- 'transactions are not shared across processes'\n\n**Reason**: SQLite uses file-level locking rather than row-level locking like PostgreSQL. This means cross-process transaction isolation works differently than in PostgreSQL's Ecto adapter.\n\n### 2. ecto_sql_compatibility_test.exs:86\n**Tag**: `@tag :skip`\n**Test**: 'fragmented schemaless types'\n\n**Reason**: SQLite does not preserve type information in schemaless queries the way PostgreSQL does. The `type(fragment(...), :integer)` syntax doesn't work the same way.\n\n## Action Items\n\n- [ ] Add `@tag :sqlite_limitation` tag to these tests for clarity\n- [ ] Add documentation in README or LIMITATIONS.md explaining these differences\n- [ ] Ensure test comments explain WHY they are skipped\n\nThese are NOT bugs to fix - they are architectural differences between SQLite and PostgreSQL that users should be aware of.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-11T16:55:19.339765+11:00","created_by":"drew","updated_at":"2026-01-11T16:55:19.339765+11:00"}
{"id":"el-6yg","title":"Fix column_default/1 crash on unexpected types","description":"PROBLEM: column_default/1 in lib/ecto/adapters/libsql/connection.ex crashes with FunctionClauseError on unexpected types (e.g., empty maps {} from Oban migrations). SOLUTION: Add catch-all clause 'defp column_default(_), do: \"\"' at end of function definition to gracefully handle unexpected types instead of crashing. IMPACT: Blocks Oban migration creation. REFERENCE: See Fix 2 in feedback document.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-13T11:57:42.146445+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T12:05:24.85969+11:00","closed_at":"2026-01-13T12:05:24.85969+11:00","close_reason":"Closed"}
{"id":"el-6zu","title":"ALTER TABLE Column Modifications (libSQL Extension)","description":"LibSQL-specific extension for modifying columns. Syntax: ALTER TABLE table_name ALTER COLUMN column_name TO column_name TYPE constraints. Can modify column types, constraints, DEFAULT values. Can add/remove foreign key constraints.\n\nThis would enable better migration support for column alterations that standard SQLite doesn't support.\n\nDesired API:\n  alter table(:users) do\n    modify :email, :string, null: false  # Actually works in libSQL!\n  end\n\nEffort: 3-4 days.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:43:58.072377+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","original_type":"feature"}
{"id":"el-7t8","title":"Full-Text Search (FTS5) Schema Integration","description":"Partial - Extension loading works, but no schema helpers. libSQL 3.45.1 has comprehensive FTS5 extension with advanced features: phrase queries, term expansion, ranking, tokenisation, custom tokenisers.\n\nDesired API:\n  create table(:posts, fts5: true) do\n    add :title, :text, fts_weight: 10\n    add :body, :text\n    add :author, :string, fts_indexed: false\n  end\n\n  from p in Post, where: fragment(\"posts MATCH ?\", \"search terms\"), order_by: [desc: fragment(\"rank\")]\n\nPRIORITY: Recommended as #7 in implementation order - major feature.\n\nEffort: 5-7 days.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:51.738732+11:00","created_by":"drew","updated_at":"2025-12-30T17:43:18.522669+11:00"}
{"id":"el-7ux","title":"Related","description":"replication_integration_test.exs (existing), savepoint_test.exs (existing)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.011021+11:00","updated_at":"2026-01-12T11:58:16.8761+11:00","closed_at":"2026-01-12T11:58:16.8761+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-8fh","title":"Test File","description":"Extend test/json_helpers_test.exs with JSONB-specific scenarios","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.011719+11:00","updated_at":"2026-01-12T11:58:16.873476+11:00","closed_at":"2026-01-12T11:58:16.873476+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-8m1","title":"Estimated Effort","description":"3-4 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.010641+11:00","updated_at":"2026-01-12T11:58:16.877372+11:00","closed_at":"2026-01-12T11:58:16.877372+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-8wn","title":"Add tests for map parameter encoding and column_default edge cases","description":"Add generic tests (not Oban-specific) to verify: 1) Map parameter encoding in test/ecto_integration_test.exs - test plain maps (not structs) are encoded to JSON before NIF calls, test nested maps, test mixed parameter types. 2) column_default/1 edge cases in test/ecto_migration_test.exs - test with nil, booleans, strings, numbers, fragments, AND unexpected types like empty maps {}. These are generic adapter features that happen to be triggered by Oban but are not Oban-specific functionality.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:58:03.328864+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T12:05:45.405497+11:00","closed_at":"2026-01-13T12:05:45.405497+11:00","close_reason":"Tests already added in el-oxv and el-6yg fixes. Map encoding tests added to test/ecto_integration_test.exs and column_default edge case tests added to test/ecto_migration_test.exs","dependencies":[{"issue_id":"el-8wn","depends_on_id":"el-oxv","type":"blocks","created_at":"2026-01-13T11:58:13.228564+11:00","created_by":"Drew Robinson"},{"issue_id":"el-8wn","depends_on_id":"el-6yg","type":"blocks","created_at":"2026-01-13T11:58:13.309034+11:00","created_by":"Drew Robinson"}]}
{"id":"el-94l","title":"Test Scenarios","description":"1. Memory usage stays constant while streaming (not loading all into memory)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.005556+11:00","updated_at":"2026-01-12T11:58:25.504053+11:00","closed_at":"2026-01-12T11:58:25.504053+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-96d","title":"Test File","description":"test/savepoint_replication_test.exs (new file)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.010242+11:00","updated_at":"2026-01-12T11:58:16.878587+11:00","closed_at":"2026-01-12T11:58:16.878587+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-9bc","title":"Documentation to Create","description":"**Rust Tests (native/ecto_libsql/src/tests/)** - Low-level correctness","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.021176+11:00","updated_at":"2026-01-12T11:58:16.859311+11:00","closed_at":"2026-01-12T11:58:16.859311+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-9c6","title":"Estimated Effort","description":"2-3 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.009546+11:00","updated_at":"2026-01-12T11:58:16.881126+11:00","closed_at":"2026-01-12T11:58:16.881126+11:00","close_reason":"Malformed fragment issue - not a valid task"}
{"id":"el-9j1","title":"Optimise LRU cache eviction for large caches","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-01T22:55:00.72463+11:00","created_by":"drew","updated_at":"2026-01-01T22:55:00.72463+11:00"}
{"id":"el-a17","title":"JSONB Binary Format Support","description":"New in libSQL 3.45. Binary encoding of JSON for faster processing. 5-10% smaller than text JSON. Backwards compatible with text JSON - automatically converted between formats. All JSON functions work with both text and JSONB.\n\nCould provide performance benefits for JSON-heavy applications. May require new Ecto type or option.\n\nEffort: 2-3 days.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-30T17:43:58.200973+11:00","created_by":"drew","updated_at":"2026-01-05T15:00:09.410754+11:00","closed_at":"2026-01-05T15:00:09.410754+11:00","close_reason":"Closed"}
{"id":"el-aob","title":"Implement True Streaming Cursors","description":"Refactor cursor implementation to use true streaming instead of loading all rows into memory.\n\n**Problem**: Current cursor implementation loads ALL rows into memory upfront (lib.rs:1074-1100), then paginates through the buffer. This causes high memory usage for large datasets.\n\n**Current (Memory Issue)**:\n```rust\n// MEMORY ISSUE (lib.rs:1074-1100):\nlet rows = query_result.into_iter().collect::\u003cVec\u003c_\u003e\u003e();  // ← Loads everything!\n```\n\n**Impact**:\n- ✅ Works fine for small/medium datasets (\u003c 100K rows)\n- ⚠️ High memory usage for large datasets (\u003e 1M rows)\n- ❌ Cannot stream truly large datasets (\u003e 10M rows)\n\n**Example**:\n```elixir\n# Current: Loads 1 million rows into RAM\ncursor = Repo.stream(large_query)\nEnum.take(cursor, 100)  # Only want 100, but loaded 1M!\n\n# Desired: True streaming, loads on-demand\ncursor = Repo.stream(large_query)\nEnum.take(cursor, 100)  # Only loads 100 rows\n```\n\n**Fix Required**:\n1. Refactor to use libsql Rows async iterator\n2. Stream batches on-demand instead of loading all upfront\n3. Store iterator state in cursor registry\n4. Fetch next batch when cursor is fetched\n5. Update CursorData structure to support streaming\n\n**Files**:\n- native/ecto_libsql/src/cursor.rs (major refactor)\n- native/ecto_libsql/src/models.rs (update CursorData struct)\n- test/ecto_integration_test.exs (add streaming tests)\n- NEW: test/performance_test.exs (memory usage benchmarks)\n\n**Acceptance Criteria**:\n- [ ] Cursors stream batches on-demand\n- [ ] Memory usage stays constant regardless of result size\n- [ ] Can stream 10M+ rows without OOM\n- [ ] Performance: Streaming vs loading all benchmarked\n- [ ] All existing cursor tests pass\n- [ ] New tests verify streaming behaviour\n\n**Test Requirements**:\n```elixir\ntest \"cursor streams 1M rows without loading all into memory\" do\n  # Insert 1M rows\n  # Declare cursor\n  # Verify memory usage \u003c 100MB while streaming\n  # Verify all rows eventually fetched\nend\n```\n\n**References**:\n- LIBSQL_FEATURE_MATRIX_FINAL.md section 9\n- FEATURE_CHECKLIST.md Cursor Methods\n\n**Priority**: P1 - Critical for large dataset processing\n**Effort**: 4-5 days (major refactor)","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-30T17:43:30.692425+11:00","created_by":"drew","updated_at":"2025-12-30T17:43:30.692425+11:00"}
{"id":"el-av5","title":"Estimated Effort","description":"1-2 hours","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.013606+11:00","updated_at":"2026-01-08T21:34:16.72622+11:00","original_type":"task"}
{"id":"el-bun","title":"Estimated Effort","description":"2-3 hours","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.008422+11:00","updated_at":"2026-01-08T21:34:16.72622+11:00","original_type":"task"}
{"id":"el-c05","title":"Work Required","description":"1. Identify redundant tests (basic type binding in Elixir)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.022572+11:00","updated_at":"2026-01-12T11:58:16.853846+11:00","closed_at":"2026-01-12T11:58:16.853846+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-c7g","title":"Merge statement_features_test.exs into prepared_statement_test.exs","description":"These two test files have significant overlap in testing prepared statements.\n\nstatement_features_test.exs (836 lines): Tests column_count, column_name, parameter_count, parameter_name, reset_stmt, get_stmt_columns, error handling\n\nprepared_statement_test.exs (464 lines): Tests preparation, execution, introspection, lifecycle, error handling\n\nDuplicate tests exist for column_count, column_name, parameter_count, and error handling.\n\nstatement_features_test.exs has newer tests (reset_stmt, get_stmt_columns, parameter_name) that should be in the canonical prepared_statement_test.exs.\n\nAction:\n1. Copy unique tests from statement_features_test.exs into prepared_statement_test.exs\n2. Reorganize test groups for clarity\n3. Delete statement_features_test.exs\n\nThis reduces test file count and eliminates duplication.\n\nEffort: 30 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:55:19.493845+11:00","created_by":"drew","updated_at":"2026-01-08T12:56:38.9178+11:00","closed_at":"2026-01-08T12:56:38.917804+11:00"}
{"id":"el-cbv","title":"Add performance benchmark tests","description":"Create comprehensive performance benchmarks to track ecto_libsql performance.\n\nFrom TEST_AUDIT_REPORT.md item 9 - no performance benchmarks currently exist.\n\n**Benchmark Categories to Implement**:\n1. Prepared statement performance (100 executions)\n2. Cursor streaming memory usage (1M rows)\n3. Concurrent connections throughput (10, 50, 100 conns)\n4. Transaction throughput (ops/sec)\n5. Batch operations performance (manual vs native vs transactional)\n6. Statement cache performance (hit rate, eviction)\n7. Replication sync performance (time per N changes)\n\n**Files to Create**:\n- benchmarks/prepared_statements_bench.exs\n- benchmarks/cursor_streaming_bench.exs\n- benchmarks/concurrent_connections_bench.exs\n- benchmarks/transactions_bench.exs\n- benchmarks/batch_operations_bench.exs\n- benchmarks/statement_cache_bench.exs\n- benchmarks/replication_bench.exs\n\n**Implementation**: Add benchee deps, create mix alias, document baselines in PERFORMANCE.md\n\n**Estimated Effort**: 2-3 days\n\n**Impact**: Track performance across versions, validate improvements, identify bottlenecks","status":"open","priority":3,"issue_type":"task","estimated_minutes":960,"created_at":"2026-01-08T21:34:57.172101+11:00","created_by":"drew","updated_at":"2026-01-08T21:34:57.172101+11:00"}
{"id":"el-crt","title":"Test savepoint + replication interaction","description":"Add tests for savepoint behavior when used with replication/remote sync.\n\nFrom TEST_AUDIT_REPORT.md item 9: 'Savepoint + replication interaction' - identified as under-tested.\n\n**Test Scenarios**:\n1. Savepoints in replica mode with sync\n2. Savepoint rollback synchronizes with remote\n3. Nested savepoints with remote sync\n4. Savepoints with failed sync scenarios\n5. Concurrent savepoints don't interfere\n6. Savepoints across sync boundaries\n\n**Test File**: test/savepoint_replication_test.exs (new)\n\n**Estimated Effort**: 3-4 hours\n\n**Related**: replication_integration_test.exs (existing), savepoint_test.exs (existing)","status":"closed","priority":2,"issue_type":"task","estimated_minutes":210,"created_at":"2026-01-08T21:34:40.300175+11:00","created_by":"drew","updated_at":"2026-01-08T21:52:54.32271+11:00","closed_at":"2026-01-08T21:52:54.32271+11:00","close_reason":"Closed"}
{"id":"el-d3o","title":"Add Rust tests for error scenarios","description":"Add comprehensive error handling tests to Rust NIF layer to verify it returns errors instead of panicking.\n\nFrom TEST_AUDIT_REPORT.md item 6: 'Add Rust Tests for Error Scenarios' - critical for BEAM stability.\n\n**Test Scenarios**:\n1. Invalid resource IDs (connection, statement, transaction, cursor)\n2. Parameter validation (count mismatch, type mismatch)\n3. Constraint violations (NOT NULL, UNIQUE, FOREIGN KEY, CHECK)\n4. Transaction errors (operations after commit, double rollback)\n5. Query syntax errors (invalid SQL, non-existent table/column)\n6. Resource exhaustion (too many prepared statements/cursors)\n\n**Test File**: native/ecto_libsql/src/tests/error_handling_tests.rs (new)\n\n**Estimated Effort**: 1-2 hours\n\n**Impact**: Verifies Rust layer doesn't crash on invalid inputs, critical for BEAM stability (no panics allowed)","status":"closed","priority":2,"issue_type":"task","estimated_minutes":90,"created_at":"2026-01-08T21:34:51.170472+11:00","created_by":"drew","updated_at":"2026-01-08T21:41:12.200622+11:00","closed_at":"2026-01-08T21:41:12.200626+11:00"}
{"id":"el-d63","title":"Test connection error recovery","description":"Add tests for connection recovery and resilience after network/connection failures.\n\nFrom TEST_AUDIT_REPORT.md item 9: 'Recovery from connection errors' - identified as under-tested.\n\n**Test Scenarios**:\n1. Connection loss during query execution\n2. Automatic reconnection on stale/idle connections\n3. Retry logic with backoff for transient errors\n4. Connection timeout handling\n5. Network partition recovery\n6. Connection state after error (no partial transactions)\n\n**Test File**: test/connection_recovery_test.exs (new)\n\n**Estimated Effort**: 2-3 hours","status":"closed","priority":2,"issue_type":"task","estimated_minutes":150,"created_at":"2026-01-08T21:34:34.659275+11:00","created_by":"drew","updated_at":"2026-01-12T11:57:15.952898+11:00","closed_at":"2026-01-12T11:57:15.952898+11:00","close_reason":"Tests implemented in test/connection_recovery_test.exs (11 tests covering error recovery scenarios)"}
{"id":"el-dcb","title":"Document Oban integration in README and AGENTS.md","description":"Add documentation for Oban integration to README.md and AGENTS.md. Must include: 1) Migration setup requiring explicit SQLite3 migrator (Oban.Migration.up(version: 1, migrator: Oban.Migrations.SQLite)), 2) Why migrator must be specified (Oban doesn't auto-detect ecto_libsql), 3) Note that ecto_libsql is fully SQLite-compatible. Add example migration code and note in compatibility/integrations section.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:57:42.292238+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T11:58:47.099384+11:00","closed_at":"2026-01-13T11:58:47.099384+11:00","close_reason":"Oban is a separate library - integration documentation belongs in Oban docs or application-level docs, not in ecto_libsql","dependencies":[{"issue_id":"el-dcb","depends_on_id":"el-oxv","type":"blocks","created_at":"2026-01-13T11:57:48.418431+11:00","created_by":"Drew Robinson"},{"issue_id":"el-dcb","depends_on_id":"el-6yg","type":"blocks","created_at":"2026-01-13T11:57:48.494457+11:00","created_by":"Drew Robinson"}]}
{"id":"el-djv","title":"Implement max_write_replication_index() NIF","description":"Add max_write_replication_index() NIF to track maximum write frame for replication monitoring.\n\n**Context**: The libsql API provides max_write_replication_index() for tracking the highest frame number that has been written. This is useful for monitoring replication lag and coordinating replica sync.\n\n**Current Status**: \n- ⚠️ LibSQL 0.9.29 provides the API\n- ⚠️ Not yet wrapped in ecto_libsql\n- Identified in LIBSQL_FEATURE_MATRIX_FINAL.md section 5\n\n**Use Case**:\n```elixir\n# Primary writes data\n{:ok, _} = Repo.query(\"INSERT INTO users (name) VALUES ('Alice')\")\n\n# Track max write frame on primary\n{:ok, max_write_frame} = EctoLibSql.Native.max_write_replication_index(primary_state)\n\n# Sync replica to that frame\n:ok = EctoLibSql.Native.sync_until(replica_state, max_write_frame)\n\n# Now replica is caught up to primary's writes\n```\n\n**Benefits**:\n- Monitor replication lag accurately\n- Coordinate multi-replica sync\n- Ensure read-after-write consistency\n- Track write progress for analytics\n\n**Implementation Required**:\n\n1. **Add NIF** (native/ecto_libsql/src/replication.rs):\n   ```rust\n   /// Get the maximum replication index that has been written.\n   ///\n   /// # Returns\n   /// - {:ok, frame_number} - Success\n   /// - {:error, reason} - Failure\n   #[rustler::nif(schedule = \"DirtyIo\")]\n   pub fn max_write_replication_index(conn_id: \u0026str) -\u003e NifResult\u003cu64\u003e {\n       let conn_map = safe_lock(\u0026CONNECTION_REGISTRY, \"max_write_replication_index\")?;\n       let conn_arc = conn_map\n           .get(conn_id)\n           .ok_or_else(|| rustler::Error::Term(Box::new(\"Connection not found\")))?\n           .clone();\n       drop(conn_map);\n\n       let result = TOKIO_RUNTIME.block_on(async {\n           let conn_guard = safe_lock_arc(\u0026conn_arc, \"max_write_replication_index conn\")\n               .map_err(|e| format!(\"{:?}\", e))?;\n           \n           conn_guard\n               .db\n               .max_write_replication_index()\n               .await\n               .map_err(|e| format!(\"Failed to get max write replication index: {:?}\", e))\n       })?;\n\n       Ok(result)\n   }\n   ```\n\n2. **Add Elixir wrapper** (lib/ecto_libsql/native.ex):\n   ```elixir\n   @doc \"\"\"\n   Get the maximum replication index that has been written.\n   \n   Returns the highest frame number that has been written to the database.\n   Useful for tracking write progress and coordinating replica sync.\n   \n   ## Examples\n   \n       {:ok, max_frame} = EctoLibSql.Native.max_write_replication_index(state)\n       :ok = EctoLibSql.Native.sync_until(replica_state, max_frame)\n   \"\"\"\n   def max_write_replication_index(_conn_id), do: :erlang.nif_error(:nif_not_loaded)\n   \n   def max_write_replication_index_safe(%EctoLibSql.State{conn_id: conn_id}) do\n     case max_write_replication_index(conn_id) do\n       {:ok, frame} -\u003e {:ok, frame}\n       {:error, reason} -\u003e {:error, reason}\n     end\n   end\n   ```\n\n3. **Add tests** (test/replication_integration_test.exs):\n   ```elixir\n   test \"max_write_replication_index tracks writes\" do\n     {:ok, state} = connect()\n     \n     # Initial max write frame\n     {:ok, initial_frame} = EctoLibSql.Native.max_write_replication_index(state)\n     \n     # Perform write\n     {:ok, _, _, state} = EctoLibSql.handle_execute(\n       \"INSERT INTO test (data) VALUES (?)\",\n       [\"test\"], [], state\n     )\n     \n     # Max write frame should increase\n     {:ok, new_frame} = EctoLibSql.Native.max_write_replication_index(state)\n     assert new_frame \u003e initial_frame\n   end\n   ```\n\n**Files**:\n- native/ecto_libsql/src/replication.rs (add NIF)\n- lib/ecto_libsql/native.ex (add wrapper)\n- test/replication_integration_test.exs (add tests)\n- AGENTS.md (update API docs)\n\n**Acceptance Criteria**:\n- [ ] max_write_replication_index() NIF implemented\n- [ ] Safe wrapper in Native module\n- [ ] Tests verify frame number increases on writes\n- [ ] Tests verify frame number coordination\n- [ ] Documentation updated\n- [ ] API added to AGENTS.md\n\n**Dependencies**:\n- Related to el-g5l (Replication Integration Tests)\n- Should be tested together\n\n**References**:\n- LIBSQL_FEATURE_MATRIX_FINAL.md section 5 (line 167)\n- libsql API: db.max_write_replication_index()\n\n**Priority**: P1 - Important for replication monitoring\n**Effort**: 0.5-1 day (straightforward NIF addition)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-30T17:45:41.941413+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"max_write_replication_index NIF already implemented in native/ecto_libsql/src/replication.rs and wrapped in lib/ecto_libsql/native.ex","original_type":"task"}
{"id":"el-doo","title":"Test cursor streaming with large result sets","description":"Implement comprehensive tests for cursor streaming behavior with large result sets (1M+).\n\nFrom TEST_AUDIT_REPORT.md item 9: 'Large result sets with streaming' - identified as under-tested.\n\n**Test Scenarios**:\n1. Memory usage stays constant while streaming (not loading all into memory)\n2. Cursor batch fetching with different batch sizes (100, 1000, 10000 rows)\n3. Cursor lifecycle (declare → fetch → close)\n4. Streaming 100K, 1M, and 10M row datasets without OOM\n5. Cursors with WHERE clause filtering on large datasets\n\n**Test File**: test/cursor_streaming_test.exs (new)\n\n**Estimated Effort**: 2-3 hours\n\n**Related**: el-aob (Implement True Streaming Cursors - feature)","status":"closed","priority":2,"issue_type":"task","estimated_minutes":150,"created_at":"2026-01-08T21:34:25.28462+11:00","created_by":"drew","updated_at":"2026-01-08T21:43:44.680239+11:00","closed_at":"2026-01-08T21:43:44.680245+11:00"}
{"id":"el-e42","title":"Add Performance Benchmark Tests","description":"Create comprehensive performance benchmarks to track ecto_libsql performance and identify bottlenecks.\n\n**Context**: No performance benchmarks exist. Need to establish baselines and track performance across versions. Critical for validating performance improvements (like statement reset fix).\n\n**Benchmark Categories**:\n\n**1. Prepared Statement Performance**:\n```elixir\n# Measure impact of statement re-preparation bug\nbenchmark \"prepared statement execution\" do\n  stmt = prepare(\"INSERT INTO bench VALUES (?, ?)\")\n  \n  # Before fix: ~30-50% slower\n  # After fix: baseline\n  Benchee.run(%{\n    \"100 executions\" =\u003e fn -\u003e \n      for i \u003c- 1..100, do: execute(stmt, [i, \"data\"])\n    end\n  })\nend\n```\n\n**2. Cursor Streaming Memory**:\n```elixir\nbenchmark \"cursor memory usage\" do\n  # Current: Loads all into memory\n  # After streaming fix: Constant memory\n  \n  cursor = declare_cursor(\"SELECT * FROM large_table\")\n  \n  :erlang.garbage_collect()\n  {memory_before, _} = :erlang.process_info(self(), :memory)\n  \n  Enum.take(cursor, 100)\n  \n  {memory_after, _} = :erlang.process_info(self(), :memory)\n  memory_used = memory_after - memory_before\n  \n  # Assert memory \u003c 10MB for 1M row table\n  assert memory_used \u003c 10_000_000\nend\n```\n\n**3. Concurrent Connections**:\n```elixir\nbenchmark \"concurrent connections\" do\n  Benchee.run(%{\n    \"10 connections\" =\u003e fn -\u003e parallel_queries(10) end,\n    \"50 connections\" =\u003e fn -\u003e parallel_queries(50) end,\n    \"100 connections\" =\u003e fn -\u003e parallel_queries(100) end,\n  })\nend\n```\n\n**4. Transaction Throughput**:\n```elixir\nbenchmark \"transaction throughput\" do\n  Benchee.run(%{\n    \"1000 transactions/sec\" =\u003e fn -\u003e\n      for i \u003c- 1..1000 do\n        Repo.transaction(fn -\u003e\n          Repo.query(\"INSERT INTO bench VALUES (?)\", [i])\n        end)\n      end\n    end\n  })\nend\n```\n\n**5. Batch Operations**:\n```elixir\nbenchmark \"batch operations\" do\n  queries = for i \u003c- 1..1000, do: \"INSERT INTO bench VALUES (\\#{i})\"\n  \n  Benchee.run(%{\n    \"manual batch\" =\u003e fn -\u003e execute_batch(queries) end,\n    \"native batch\" =\u003e fn -\u003e execute_batch_native(queries) end,\n    \"transactional batch\" =\u003e fn -\u003e execute_transactional_batch(queries) end,\n  })\nend\n```\n\n**6. Statement Cache Performance**:\n```elixir\nbenchmark \"statement cache\" do\n  Benchee.run(%{\n    \"1000 unique statements\" =\u003e fn -\u003e\n      for i \u003c- 1..1000 do\n        prepare(\"SELECT * FROM bench WHERE id = \\#{i}\")\n      end\n    end\n  })\nend\n```\n\n**7. Replication Sync Performance**:\n```elixir\nbenchmark \"replica sync\" do\n  # Write to primary\n  for i \u003c- 1..10000, do: insert_on_primary(i)\n  \n  # Measure sync time\n  Benchee.run(%{\n    \"sync 10K changes\" =\u003e fn -\u003e \n      sync(replica)\n    end\n  })\nend\n```\n\n**Implementation**:\n\n1. **Add benchee dependency** (mix.exs):\n   ```elixir\n   {:benchee, \"~\u003e 1.3\", only: :dev}\n   {:benchee_html, \"~\u003e 1.0\", only: :dev}\n   ```\n\n2. **Create benchmark files**:\n   - benchmarks/prepared_statements_bench.exs\n   - benchmarks/cursor_streaming_bench.exs\n   - benchmarks/concurrent_connections_bench.exs\n   - benchmarks/transactions_bench.exs\n   - benchmarks/batch_operations_bench.exs\n   - benchmarks/statement_cache_bench.exs\n   - benchmarks/replication_bench.exs\n\n3. **Add benchmark runner** (mix.exs):\n   ```elixir\n   def cli do\n     [\n       aliases: [\n         bench: \"run benchmarks/**/*_bench.exs\"\n       ]\n     ]\n   end\n   ```\n\n4. **CI Integration**:\n   - Run benchmarks on PRs\n   - Track performance over time\n   - Alert on regression \u003e 20%\n\n**Baseline Targets** (to establish):\n- Prepared statement execution: X ops/sec\n- Cursor streaming: Y MB memory for Z rows\n- Transaction throughput: 1000+ txn/sec\n- Concurrent connections: 100 connections\n- Batch operations: Native 20-30% faster than manual\n\n**Files**:\n- mix.exs (add benchee dependency)\n- benchmarks/*.exs (benchmark files)\n- .github/workflows/benchmarks.yml (CI integration)\n- PERFORMANCE.md (document baselines and results)\n\n**Acceptance Criteria**:\n- [ ] Benchee dependency added\n- [ ] 7 benchmark categories implemented\n- [ ] Benchmarks run via mix bench\n- [ ] HTML reports generated\n- [ ] Baselines documented in PERFORMANCE.md\n- [ ] CI runs benchmarks on PRs\n- [ ] Regression alerts configured\n\n**Test Requirements**:\n```bash\n# Run all benchmarks\nmix bench\n\n# Run specific benchmark\nmix run benchmarks/prepared_statements_bench.exs\n\n# Generate HTML report\nmix run benchmarks/prepared_statements_bench.exs --format html\n```\n\n**Benefits**:\n- Track performance across versions\n- Validate performance improvements\n- Identify bottlenecks\n- Catch regressions early\n- Document performance characteristics\n\n**References**:\n- FEATURE_CHECKLIST.md section \"Test Coverage Priorities\" item 6\n- LIBSQL_FEATURE_COMPARISON.md section \"Performance and Stress Tests\"\n\n**Dependencies**:\n- Validates fixes for el-2ry (statement performance bug)\n- Validates fixes for el-aob (streaming cursors)\n\n**Priority**: P3 - Nice to have, tracks quality over time\n**Effort**: 2-3 days","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T17:46:14.715332+11:00","created_by":"drew","updated_at":"2025-12-30T17:46:14.715332+11:00"}
{"id":"el-e9r","title":"Add boolean encoding support in query parameters","description":"Boolean values in raw query parameters (e.g., Repo.all(from u in User, where: u.active == ^true)) may not be encoded to SQLite's 0/1 format. Verify if dumpers handle this case, or if encode_param needs explicit boolean handling. Add tests for boolean query parameters and implement encoding if needed (true -\u003e 1, false -\u003e 0).","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:53:06.689429+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T14:46:51.299825+11:00","closed_at":"2026-01-13T14:46:51.299825+11:00","close_reason":"Closed","dependencies":[{"issue_id":"el-e9r","depends_on_id":"el-5mr","type":"blocks","created_at":"2026-01-13T11:53:35.390548+11:00","created_by":"Drew Robinson"}]}
{"id":"el-f0x","title":"Related","description":"el-aob (Implement True Streaming Cursors - feature)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.007037+11:00","updated_at":"2026-01-12T11:58:16.887445+11:00","closed_at":"2026-01-12T11:58:16.887445+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-fd8","title":"Test connection pool behavior under load","description":"Add tests for connection pool behavior when under concurrent load.\n\nFrom TEST_AUDIT_REPORT.md item 9: 'Connection pool behavior under load' - identified as under-tested.\n\n**Test Scenarios**:\n1. Concurrent connections at different pool sizes (5, 10, 50, 100)\n2. Connection exhaustion and queue behavior  \n3. Connection recovery after failure/close\n4. Load distribution across pool connections\n5. Long-running queries don't block quick queries\n6. Pool cleanup and resource leak prevention\n\n**Test File**: test/pool_load_test.exs (new)\n\n**Estimated Effort**: 2-3 hours","status":"closed","priority":2,"issue_type":"task","estimated_minutes":150,"created_at":"2026-01-08T21:34:30.586026+11:00","created_by":"drew","updated_at":"2026-01-08T21:52:54.375281+11:00","closed_at":"2026-01-08T21:52:54.375281+11:00","close_reason":"Closed"}
{"id":"el-ffc","title":"EXPLAIN Query Support","description":"Not implemented in ecto_libsql. libSQL 3.45.1 fully supports EXPLAIN and EXPLAIN QUERY PLAN for query optimiser insight.\n\nDesired API:\n  query = from u in User, where: u.age \u003e 18\n  {:ok, plan} = Repo.explain(query)\n  # Or: Ecto.Adapters.SQL.explain(Repo, :all, query)\n\nPRIORITY: Recommended as #3 in implementation order - quick win for debugging.\n\nEffort: 2-3 days.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:52.299542+11:00","created_by":"drew","updated_at":"2026-01-08T13:37:35.641939+11:00","closed_at":"2026-01-08T13:37:35.641948+11:00","labels":["status:in-progress"]}
{"id":"el-ffc.1","title":"State change: status → in-progress","description":"Set status to in-progress","status":"closed","priority":4,"issue_type":"event","created_at":"2026-01-06T19:20:27.022845+11:00","created_by":"drew","updated_at":"2026-01-08T13:02:28.373261+11:00","closed_at":"2026-01-08T13:02:28.373264+11:00","dependencies":[{"issue_id":"el-ffc.1","depends_on_id":"el-ffc","type":"parent-child","created_at":"2026-01-06T19:20:27.023871+11:00","created_by":"drew"}]}
{"id":"el-fpi","title":"Fix binary data round-trip property test failure for single null byte","description":"## Problem\n\nThe property test for binary data handling is failing when the generated binary is a single null byte ().\n\n## Failure Details\n\n\n\n**File**: test/fuzz_test.exs:736\n**Test**: property binary data handling round-trips binary data correctly\n\n## Root Cause\n\nWhen a single null byte () is stored in the database as a BLOB and retrieved, it's being returned as an empty string () instead of the original binary.\n\nThis suggests a potential issue with:\n1. Binary encoding/decoding in the Rust NIF layer (decode.rs)\n2. Type conversion in the Elixir loaders/dumpers\n3. Handling of edge case binaries (single null byte, empty blobs)\n\n## Impact\n\n- Property-based test failures indicate the binary data handling isn't robust for all valid binary inputs\n- Applications storing binary data with null bytes may experience data corruption\n- Affects blob storage reliability\n\n## Reproduction\n\n\n\n## Investigation Areas\n\n1. **native/ecto_libsql/src/decode.rs** - Check Value::Blob conversion\n2. **lib/ecto/adapters/libsql.ex** - Check binary loaders/dumpers\n3. **native/ecto_libsql/src/query.rs** - Verify blob retrieval logic\n4. **Test edge cases**: , , , \n\n## Expected Behavior\n\nAll binaries (including single null byte) should round-trip correctly:\n- Store  → Retrieve \n- Store  → Retrieve \n- Store  → Retrieve \n\n## Related Code\n\n- test/fuzz_test.exs:736-753\n- native/ecto_libsql/src/decode.rs (blob handling)\n- lib/ecto/adapters/libsql.ex (type loaders/dumpers)","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-30T18:05:52.838065+11:00","created_by":"drew","updated_at":"2026-01-13T17:52:29.359724+11:00","closed_at":"2026-01-13T17:52:29.359724+11:00","close_reason":"Added test coverage for single null byte binary in type_encoding_implementation_test.exs:517. Test confirms the bug: \u003c\u003c0\u003e\u003e (single null byte) is being returned as '' (empty string). This is a round-trip failure in binary data handling. Bug confirmed at NIF/decode layer. Deferring actual fix to separate implementation issue.","original_type":"bug"}
{"id":"el-g5l","title":"Replication Integration Tests","description":"Add comprehensive integration tests for replication features.\n\n**Context**: Replication features are implemented but have minimal test coverage (marked as ⚠️ in FEATURE_CHECKLIST.md).\n\n**Required Tests** (test/replication_integration_test.exs):\n- sync_until() - frame-specific sync\n- flush_replicator() - force pending writes  \n- max_write_replication_index() - write tracking\n- replication_index() - current frame tracking\n\n**Test Scenarios**:\n1. Monitor replication lag via frame numbers\n2. Sync to specific frame number\n3. Flush pending writes and verify frame number\n4. Track max write frame across operations\n\n**Files**:\n- NEW: test/replication_integration_test.exs\n- Reference: FEATURE_CHECKLIST.md line 212-242\n- Reference: LIBSQL_FEATURE_MATRIX_FINAL.md section 5\n\n**Acceptance Criteria**:\n- [ ] All 4 replication NIFs have comprehensive tests\n- [ ] Tests cover happy path and edge cases\n- [ ] Tests verify frame number progression\n- [ ] Tests validate sync behaviour\n\n**Priority**: P1 - Critical for Turso use cases\n**Effort**: 2-3 days","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T17:42:37.162327+11:00","created_by":"drew","updated_at":"2026-01-12T11:57:16.258516+11:00","closed_at":"2026-01-12T11:57:16.258516+11:00","close_reason":"Tests implemented in test/replication_integration_test.exs (24 tests) covering frame tracking, sync, flush operations","original_type":"task"}
{"id":"el-gwo","title":"Add atom encoding support for :null in query parameters","description":"The atom :null is sometimes used in Elixir code to represent SQL NULL. Verify if SQLite/LibSQL handles :null atom correctly, or if it should be converted to nil. Add encode_param(:null) clause if conversion is needed. Also consider if other atoms should be handled or should raise an error for better debugging.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-13T11:53:06.840348+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T14:46:51.442471+11:00","closed_at":"2026-01-13T14:46:51.442471+11:00","close_reason":"Closed","dependencies":[{"issue_id":"el-gwo","depends_on_id":"el-5mr","type":"blocks","created_at":"2026-01-13T11:53:35.458852+11:00","created_by":"Drew Robinson"}]}
{"id":"el-h0i","title":"Document limitations for nested structures with temporal types","description":"Nested structures in query parameters (e.g., maps/lists containing DateTime/Decimal values) are not recursively encoded. Document in AGENTS.md that users should pre-encode nested structures before passing to queries. Example: %{metadata: %{created_at: DateTime.utc_now()}} will fail. Add to limitations section with workaround examples.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-13T11:53:06.976923+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T14:46:51.513889+11:00","closed_at":"2026-01-13T14:46:51.513889+11:00","close_reason":"Closed"}
{"id":"el-h48","title":"Table-Valued Functions (via Extensions)","description":"Not implemented. Generate rows from functions, series generation, CSV parsing. Examples: generate_series(1, 10), csv_table(path, schema). Effort: 4-5 days (if building custom extension).","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-30T17:35:53.485837+11:00","created_by":"drew","updated_at":"2025-12-30T17:36:47.67121+11:00"}
{"id":"el-i0v","title":"Connection Reset and Interrupt Functional Tests","description":"Add comprehensive functional tests for connection reset and interrupt features.\n\n**Context**: reset_connection and interrupt_connection are implemented but only have basic tests (marked as ⚠️ in FEATURE_CHECKLIST.md).\n\n**Required Tests** (expand test/connection_features_test.exs or create new):\n\n**Reset Tests**:\n- Reset maintains database connection\n- Reset allows connection reuse in pool\n- Reset doesn't close active transactions\n- Reset clears temporary state\n- Reset multiple times in succession\n\n**Interrupt Tests**:\n- Interrupt cancels long-running query\n- Interrupt allows query restart after cancellation\n- Interrupt doesn't affect other connections\n- Interrupt during transaction behaviour\n- Concurrent interrupts on different connections\n\n**Files**:\n- EXPAND/NEW: test/connection_features_test.exs\n- Reference: FEATURE_CHECKLIST.md line 267-287\n- Reference: LIBSQL_FEATURE_COMPARISON.md section 3\n\n**Test Examples**:\n```elixir\ntest \"reset maintains database connection\" do\n  {:ok, state} = connect()\n  {:ok, state} = reset_connection(state)\n  # Verify connection still works\n  {:ok, _, _, _} = query(state, \"SELECT 1\")\nend\n\ntest \"interrupt cancels long-running query\" do\n  {:ok, state} = connect()\n  # Start long query in background\n  task = Task.async(fn -\u003e query(state, \"SELECT sleep(10)\") end)\n  # Interrupt after 100ms\n  Process.sleep(100)\n  interrupt_connection(state)\n  # Verify query was cancelled\n  assert {:error, _} = Task.await(task)\nend\n```\n\n**Acceptance Criteria**:\n- [ ] Reset functional tests comprehensive\n- [ ] Interrupt functional tests comprehensive\n- [ ] Tests verify connection state after reset/interrupt\n- [ ] Tests verify connection pool behaviour\n- [ ] Tests cover edge cases and error conditions\n\n**Priority**: P1 - Important for production robustness\n**Effort**: 2 days","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T17:43:00.235086+11:00","created_by":"drew","updated_at":"2026-01-12T11:57:16.066193+11:00","closed_at":"2026-01-12T11:57:16.066193+11:00","close_reason":"Tests implemented in test/connection_features_test.exs - reset tests (6) and interrupt tests (6) cover required scenarios","original_type":"task"}
{"id":"el-i3j","title":"Test File","description":"test/connection_recovery_test.exs (new file)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.009202+11:00","updated_at":"2026-01-12T11:58:16.882424+11:00","closed_at":"2026-01-12T11:58:16.882424+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-i9r","title":"Impact","description":"- Verifies Rust layer doesn't crash on invalid inputs","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.015013+11:00","updated_at":"2026-01-12T11:58:16.867441+11:00","closed_at":"2026-01-12T11:58:16.867441+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-ik6","title":"Generated/Computed Columns","description":"Not supported in migrations. SQLite 3.31+ (2020), libSQL 3.45.1 fully supports GENERATED ALWAYS AS syntax with both STORED and virtual variants.\n\nDesired API:\n  create table(:users) do\n    add :first_name, :string\n    add :last_name, :string\n    add :full_name, :string, generated: \"first_name || ' ' || last_name\", stored: true\n  end\n\nPRIORITY: Recommended as #4 in implementation order.\n\nEffort: 3-4 days.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:51.391724+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Feature was already implemented with tests. Added documentation to AGENTS.md covering: GENERATED ALWAYS AS syntax, STORED vs VIRTUAL variants, constraints (no DEFAULT, no PRIMARY KEY), and usage examples.","original_type":"feature"}
{"id":"el-jlb","title":"Implementation","description":"- Add benchee (~1.3) and benchee_html dependencies","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.020058+11:00","updated_at":"2026-01-12T11:58:16.863372+11:00","closed_at":"2026-01-12T11:58:16.863372+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-l4i","title":"TEST: Verify beads sync works","status":"closed","priority":4,"issue_type":"task","created_at":"2026-01-12T12:26:24.820195+11:00","created_by":"drew","updated_at":"2026-01-12T12:26:37.291005+11:00","closed_at":"2026-01-12T12:26:37.291005+11:00","close_reason":"Test issue - verified beads sync works"}
{"id":"el-lkm","title":"Test File","description":"native/ecto_libsql/src/tests/error_handling_tests.rs (new file)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.013205+11:00","updated_at":"2026-01-12T11:58:16.868654+11:00","closed_at":"2026-01-12T11:58:16.868654+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-m1w","title":"Clean up ecto_libsql_test.exs - move tests to appropriate files","description":"ecto_libsql_test.exs (681 lines) is a mixed bag of tests. It contains:\n\nTests that should be moved:\n- 'vector' test → belongs in vector_geospatial_test.exs\n- 'prepare and execute a simple select' → belongs in prepared_statement_test.exs\n- 'create table' → belongs in ecto_migration_test.exs\n- 'transaction and param' → belongs in savepoint_test.exs or ecto_sql_transaction_compat_test.exs\n- 'explain query' → belongs in explain_query_test.exs\n\nTests to keep (these are legitimate smoke tests):\n- 'connection remote replica'\n- 'ping connection'\n\nAfter consolidation:\n1. Rename to smoke_test.exs to clarify it's a smoke test file\n2. Add documentation explaining it's for basic sanity checking\n3. Keep line count to ~100-150 lines max\n\nEffort: 45 minutes\nImpact: Reduce maintenance burden, clearer test intent, eliminates false duplication signals","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:55:28.591032+11:00","created_by":"drew","updated_at":"2026-01-08T12:57:17.356324+11:00","closed_at":"2026-01-08T12:57:17.356337+11:00"}
{"id":"el-m99","title":"Optimise ETS cache eviction to avoid O(n log n) scan","description":"## Location\n`lib/ecto_libsql/native.ex` lines 508-518\n\n## Current Behaviour\n`evict_oldest_entries/0` calls `:ets.tab2list/1`, loading all 1000 entries into memory, then sorts by access time. This is O(n log n) on every cache overflow.\n\nWith max 1000 entries and evictions removing 500 at a time, this runs infrequently enough to be acceptable, but worth noting for future optimisation if cache size increases.\n\n## Suggested Alternative\nUse a separate `:ordered_set` table keyed by access time for O(1) oldest entry lookup.\n\nHowever, the current implementation is adequate for the documented 1000-entry limit - only pursue if cache size needs to increase significantly.\n\n## Priority\nP4 (backlog) - Only optimise if profiling shows this is a bottleneck.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-02T17:08:56.805305+11:00","created_by":"drew","updated_at":"2026-01-02T17:09:03.848554+11:00"}
{"id":"el-mla","title":"Test Scenarios","description":"1. Concurrent connections at different pool sizes (5, 10, 50, 100)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.007432+11:00","updated_at":"2026-01-12T11:58:16.886192+11:00","closed_at":"2026-01-12T11:58:16.886192+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-ndz","title":"UPSERT Support (INSERT ... ON CONFLICT)","description":"INSERT ... ON CONFLICT not implemented in ecto_libsql. SQLite 3.24+ (2018), libSQL 3.45.1 fully supports all conflict resolution modes: INSERT OR IGNORE, INSERT OR REPLACE, REPLACE, INSERT OR FAIL, INSERT OR ABORT, INSERT OR ROLLBACK.\n\nDesired API:\n  Repo.insert(changeset, on_conflict: :replace_all, conflict_target: [:email])\n  Repo.insert(changeset, on_conflict: {:replace, [:name, :updated_at]}, conflict_target: [:email])\n\nPRIORITY: Recommended as #2 in implementation order - common pattern, high value.\n\nEffort: 4-5 days.","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-30T17:35:51.230695+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Implemented query-based on_conflict support for UPSERT operations. Basic UPSERT was already implemented; added support for keyword list syntax [set: [...], inc: [...]].","original_type":"feature"}
{"id":"el-nms","title":"Benchmark Categories","description":"1. Prepared statement performance (100 executions)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.015451+11:00","updated_at":"2026-01-12T11:58:16.866149+11:00","closed_at":"2026-01-12T11:58:16.866149+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-nqb","title":"Implement Named Parameters Support","description":"Add support for named parameters in queries (:name, @name, $name syntax).\n\n**Context**: LibSQL supports named parameters but ecto_libsql only supports positional (?). This is marked as high priority in FEATURE_CHECKLIST.md.\n\n**Current Limitation**:\n```elixir\n# Only positional parameters work:\nquery(\"INSERT INTO users VALUES (?, ?)\", [1, \"Alice\"])\n\n# Named parameters don't work:\nquery(\"INSERT INTO users (id, name) VALUES (:id, :name)\", %{id: 1, name: \"Alice\"})\n```\n\n**LibSQL Support**:\n- :name syntax (standard SQLite)\n- @name syntax (alternative)\n- $name syntax (PostgreSQL-like)\n\n**Benefits**:\n- Better developer experience\n- Self-documenting queries\n- Order-independent parameters\n- Matches PostgreSQL Ecto conventions\n\n**Implementation Required**:\n\n1. **Add parameter_name() NIF**:\n   - Implement in native/ecto_libsql/src/statement.rs\n   - Expose parameter_name(stmt_id, index) -\u003e {:ok, name} | {:error, reason}\n\n2. **Update query parameter handling**:\n   - Accept map parameters: %{id: 1, name: \"Alice\"}\n   - Convert named params to positional based on statement introspection\n   - Maintain backwards compatibility with positional params\n\n3. **Update Ecto.Adapters.LibSql.Connection**:\n   - Generate SQL with named parameters for better readability\n   - Convert Ecto query bindings to named params\n\n**Files**:\n- native/ecto_libsql/src/statement.rs (add parameter_name NIF)\n- lib/ecto_libsql/native.ex (wrapper for parameter_name)\n- lib/ecto_libsql.ex (update parameter handling)\n- lib/ecto/adapters/libsql/connection.ex (generate named params)\n- test/statement_features_test.exs (tests marked :skip)\n\n**Existing Tests**:\nTests already exist but are marked :skip (mentioned in FEATURE_CHECKLIST.md line 1)\n\n**Acceptance Criteria**:\n- [ ] parameter_name() NIF implemented\n- [ ] Queries accept map parameters\n- [ ] All 3 syntaxes work (:name, @name, $name)\n- [ ] Backwards compatible with positional params\n- [ ] Unskip and pass existing tests\n- [ ] Add comprehensive named parameter tests\n\n**Examples**:\n```elixir\n# After implementation:\nRepo.query(\"INSERT INTO users (id, name) VALUES (:id, :name)\", %{id: 1, name: \"Alice\"})\nRepo.query(\"UPDATE users SET name = @name WHERE id = @id\", %{id: 1, name: \"Bob\"})\n```\n\n**References**:\n- FEATURE_CHECKLIST.md section \"High Priority (Should Implement)\" item 1\n- Test file with :skip markers\n\n**Priority**: P1 - High priority, improves developer experience\n**Effort**: 2-3 days","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-30T17:43:47.792238+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Implemented named parameter execution support with transparent conversion from map-based to positional parameters. Supports all three SQLite syntaxes (:name, @name, $name). Added comprehensive test coverage and documentation in AGENTS.md.","original_type":"feature"}
{"id":"el-o8r","title":"Partial Index Support in Migrations","description":"SQLite supports but Ecto DSL doesn't. Index only subset of rows, smaller/faster indexes, better for conditional uniqueness. Desired API: create index(:users, [:email], unique: true, where: \"deleted_at IS NULL\"). Effort: 2-3 days.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:52.699216+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","original_type":"feature"}
{"id":"el-olq","title":"Test Scenarios","description":"1. JSONB round-trip correctness (text → JSONB → text)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.011388+11:00","updated_at":"2026-01-12T11:58:16.874751+11:00","closed_at":"2026-01-12T11:58:16.874751+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-oxv","title":"Fix map parameter encoding to JSON before NIF calls","description":"PROBLEM: Oban passes job args as plain Elixir maps, but Rust NIF cannot serialize map types, causing 'Unsupported argument type' errors. SOLUTION: Add encode_parameters/1 function in lib/ecto_libsql/native.ex to convert plain maps (not structs) to JSON strings before passing to NIF. Must be called in: 1) do_query/6 before query_args call, 2) do_execute_with_trx/6 before query_with_trx_args and execute_with_transaction calls. IMPACT: Blocks Oban job insertion with complex args. REFERENCE: See Fix 1 in feedback document for exact implementation.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-13T11:57:41.983055+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T12:02:53.058317+11:00","closed_at":"2026-01-13T12:02:53.058317+11:00","close_reason":"Closed"}
{"id":"el-oya","title":"Test File","description":"test/pool_load_test.exs (new file)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.008032+11:00","updated_at":"2026-01-12T11:58:16.884944+11:00","closed_at":"2026-01-12T11:58:16.884944+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-pez","title":"Impact","description":"Reduce test maintenance, focus on higher-level scenarios","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.023631+11:00","updated_at":"2026-01-12T11:58:16.848433+11:00","closed_at":"2026-01-12T11:58:16.848433+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-phd","title":"Test Scenarios","description":"1. Connection loss during query execution","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.008833+11:00","updated_at":"2026-01-12T11:58:16.883723+11:00","closed_at":"2026-01-12T11:58:16.883723+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-pre","title":"Add UUID encoding support in query parameters","description":"Query parameters may contain Ecto.UUID structs (e.g., Repo.get_by(User, uuid: %Ecto.UUID{...})). Currently these pass through without encoding, which may cause NIF errors. Add encode_param(%Ecto.UUID{}) clause to convert to string representation. Check if Ecto.UUID.dump/1 or to_string/1 is appropriate.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:53:06.551832+11:00","created_by":"Drew Robinson","updated_at":"2026-01-13T14:46:51.370151+11:00","closed_at":"2026-01-13T14:46:51.370151+11:00","close_reason":"Closed","dependencies":[{"issue_id":"el-pre","depends_on_id":"el-5mr","type":"blocks","created_at":"2026-01-13T11:53:35.311292+11:00","created_by":"Drew Robinson"}]}
{"id":"el-q7e","title":"Consolidate explain_query_test.exs and explain_simple_test.exs","description":"Both test EXPLAIN query functionality with overlapping test cases.\n\nexplain_query_test.exs (262 lines): Comprehensive Ecto setup with full test coverage\nexplain_simple_test.exs (115 lines): Simpler test setup (appears to be a debugging artifact from development)\n\nAction:\n1. Review explain_simple_test.exs for any unique test cases\n2. Move any unique tests to explain_query_test.exs\n3. Delete explain_simple_test.exs\n4. Keep explain_query_test.exs as the canonical EXPLAIN test file\n\nEffort: 15 minutes\nImpact: Remove redundant test file, single source of truth for EXPLAIN testing","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:55:23.780014+11:00","created_by":"drew","updated_at":"2026-01-08T12:56:49.924299+11:00","closed_at":"2026-01-08T12:56:49.924302+11:00"}
{"id":"el-qjf","title":"ANALYZE Statistics Collection","description":"Not exposed. Better query planning, automatic index selection, performance optimisation. Desired API: EctoLibSql.Native.analyze(state), EctoLibSql.Native.analyze_table(state, \"users\"), and config auto_analyze: true for post-migration. Effort: 2 days.","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-30T17:35:52.489236+11:00","created_by":"drew","updated_at":"2025-12-30T17:36:46.862645+11:00"}
{"id":"el-qvs","title":"Statement Introspection Edge Case Tests","description":"Expand statement introspection tests to cover edge cases and complex scenarios.\n\n**Context**: Statement introspection features (parameter_count, column_count, column_name) are implemented but only have basic happy-path tests (marked as ⚠️ in FEATURE_CHECKLIST.md).\n\n**Required Tests** (expand test/statement_features_test.exs):\n- Parameter count with 0 parameters\n- Parameter count with many parameters (\u003e10)\n- Parameter count with duplicate parameters\n- Column count for SELECT *\n- Column count for complex JOINs with aliases\n- Column count for aggregate functions\n- Column names with AS aliases\n- Column names for expressions and computed columns\n- Column names for all types (INTEGER, TEXT, BLOB, REAL)\n\n**Files**:\n- EXPAND: test/statement_features_test.exs (or create new file)\n- Reference: FEATURE_CHECKLIST.md line 245-264\n- Reference: LIBSQL_FEATURE_COMPARISON.md section 2\n\n**Test Examples**:\n```elixir\n# Edge case: No parameters\nstmt = prepare(\"SELECT * FROM users\")\nassert parameter_count(stmt) == 0\n\n# Edge case: Many parameters\nstmt = prepare(\"INSERT INTO users VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\")\nassert parameter_count(stmt) == 10\n\n# Edge case: SELECT * column count\nstmt = prepare(\"SELECT * FROM users\")\nassert column_count(stmt) == actual_column_count\n\n# Edge case: Complex JOIN\nstmt = prepare(\"SELECT u.id, p.name AS profile_name FROM users u JOIN profiles p ON u.id = p.user_id\")\nassert column_name(stmt, 1) == \"profile_name\"\n```\n\n**Acceptance Criteria**:\n- [ ] All edge cases tested\n- [ ] Tests verify correct counts and names\n- [ ] Tests cover complex queries (JOINs, aggregates, expressions)\n- [ ] Tests validate column name aliases\n\n**Priority**: P1 - Important for tooling/debugging\n**Effort**: 1-2 days","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T17:42:49.190861+11:00","created_by":"drew","updated_at":"2026-01-12T11:57:16.160452+11:00","closed_at":"2026-01-12T11:57:16.160452+11:00","close_reason":"Tests implemented in test/prepared_statement_test.exs (44 tests) including edge cases: 0 params, many params, SELECT *, aliases, etc.","original_type":"task"}
{"id":"el-r7j","title":"Estimated Effort","description":"2-3 days","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.020446+11:00","updated_at":"2026-01-12T11:58:16.862079+11:00","closed_at":"2026-01-12T11:58:16.862079+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-trm","title":"Related","description":"el-a17 (JSONB Binary Format Support - feature, closed)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.012449+11:00","updated_at":"2026-01-12T11:58:16.871006+11:00","closed_at":"2026-01-12T11:58:16.871006+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-up3","title":"Estimated Effort","description":"2-3 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.012087+11:00","updated_at":"2026-01-12T11:58:16.872167+11:00","closed_at":"2026-01-12T11:58:16.872167+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-v3v","title":"Reduce redundant parameter binding tests","description":"Remove duplicate basic parameter binding tests from Elixir since Rust already covers them.\n\nFrom TEST_AUDIT_REPORT.md item 8: 'Reduce Redundant Parameter Binding Tests' - Rust tests integers, floats, text, NULL, BLOB.\n\n**Work Required**:\n1. Identify redundant tests (basic type binding in Elixir)\n2. Remove Elixir duplicates\n3. Keep Elixir tests for:\n   - Named parameters (unique to Elixir)\n   - Complex scenarios (maps, nested)\n   - Ecto-specific coercion\n\n**Files to Check**:\n- ecto_libsql_test.exs (after cleanup)\n- prepared_statement_test.exs\n- Other test files with parameter binding\n\n**Estimated Effort**: 30 minutes\n\n**Impact**: Reduce test maintenance, focus on higher-level scenarios","status":"closed","priority":3,"issue_type":"task","estimated_minutes":30,"created_at":"2026-01-08T21:35:08.481966+11:00","created_by":"drew","updated_at":"2026-01-13T17:51:42.194385+11:00","closed_at":"2026-01-13T17:51:42.194385+11:00","close_reason":"Analyzed test redundancy. ecto_libsql_query_encoding_test.exs tests protocol encode/decode functions (unit tests). type_encoding_implementation_test.exs tests through actual DB queries (integration). Basic parameter tests exist in both, but the redundancy is acceptable because: (1) different files/purposes, (2) integration tests verify DBConnection layer, (3) simple type tests are only ~10-15 lines, (4) complex tests (aggregates, edge cases) provide real value. This is acceptable technical debt for test clarity."}
{"id":"el-vnu","title":"Expression Indexes","description":"SQLite supports but awkward in Ecto. Index computed values, case-insensitive searches, JSON field indexing. Desired API: create index(:users, [], expression: \"LOWER(email)\", unique: true) or via fragment. Effort: 3 days.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-30T17:35:52.893501+11:00","created_by":"drew","updated_at":"2025-12-30T17:36:47.184024+11:00"}
{"id":"el-wee","title":"Window Functions Query Helpers","description":"libSQL 3.45.1 has full window function support: OVER, PARTITION BY, ORDER BY, frame specifications (ROWS BETWEEN, RANGE BETWEEN). Currently works via fragments but could benefit from dedicated query helpers.\n\nDesired API:\n  from u in User,\n    select: %{\n      name: u.name,\n      running_total: over(sum(u.amount), partition_by: u.category, order_by: u.date)\n    }\n\nEffort: 4-5 days.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-30T17:43:58.330639+11:00","created_by":"drew","updated_at":"2025-12-30T17:43:58.330639+11:00"}
{"id":"el-wtl","title":"Test JSONB binary format operations","description":"Verify JSONB binary format works correctly and compare performance vs text JSON.\n\nFrom TEST_AUDIT_REPORT.md item 9: 'JSON with JSONB binary format' - identified as possibly under-tested.\n\n**Test Scenarios**:\n1. JSONB round-trip correctness (text → JSONB → text)\n2. JSONB and text JSON compatibility (same results)\n3. JSONB storage size efficiency (5-10% smaller expected)\n4. JSONB query performance vs text JSON\n5. JSONB with large objects (10MB+)\n6. JSONB modification (json_set, json_replace) preserves format\n7. JSONB array operations\n\n**Test File**: Extend test/json_helpers_test.exs with JSONB-specific scenarios\n\n**Estimated Effort**: 2-3 hours\n\n**Related**: el-a17 (JSONB Binary Format Support - feature, closed)","status":"closed","priority":2,"issue_type":"task","estimated_minutes":150,"created_at":"2026-01-08T21:34:45.771272+11:00","created_by":"drew","updated_at":"2026-01-08T21:42:14.924802+11:00","closed_at":"2026-01-08T21:42:14.924806+11:00"}
{"id":"el-wvb","title":"Test Scenarios","description":"1. Invalid resource IDs (connection, statement, transaction, cursor)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.012837+11:00","updated_at":"2026-01-12T11:58:16.869842+11:00","closed_at":"2026-01-12T11:58:16.869842+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-x0d","title":"Clarify relationship between error_demo_test.exs and error_handling_test.exs","description":"Both files test error handling with potential duplication:\n\nerror_demo_test.exs (146 lines): Demonstration tests showing that errors are handled gracefully (no VM crashes)\nerror_handling_test.exs (250 lines): Comprehensive error handling tests\n\nNeed to determine:\n1. Do these test the same scenarios? (likely yes, with different focus)\n2. Is there duplication that needs consolidation?\n3. Should one be merged into the other?\n\nAction:\n1. Review both files side-by-side for duplication\n2. If same scope: merge into error_handling_test.exs and delete error_demo_test.exs\n3. If different scope: clarify names (maybe 'error_demo_test.exs' → 'error_no_crash_demo_test.exs')\n\nEffort: 30 minutes\nImpact: Clearer error testing strategy, reduce maintenance","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:55:37.011137+11:00","created_by":"drew","updated_at":"2026-01-08T12:57:49.547828+11:00","closed_at":"2026-01-08T12:57:49.54783+11:00"}
{"id":"el-x8b","title":"Files to Create","description":"- benchmarks/prepared_statements_bench.exs","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.015966+11:00","updated_at":"2026-01-12T11:58:16.86485+11:00","closed_at":"2026-01-12T11:58:16.86485+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-xih","title":"RETURNING Enhancement for Batch Operations","description":"Works for single operations, not batches. libSQL 3.45.1 supports RETURNING clause on INSERT/UPDATE/DELETE.\n\nDesired API:\n  {count, rows} = Repo.insert_all(User, users, returning: [:id, :inserted_at])\n  # Returns all inserted rows with IDs\n\nPRIORITY: Recommended as #9 in implementation order.\n\nEffort: 3-4 days.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:53.70112+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Feature is already implemented. insert_all with returning: option works correctly. Added test 'insert_all with returning option' to verify. SQL generation correctly produces 'RETURNING \"id\",\"inserted_at\"' clause. Note: update_all/delete_all use Ecto's select: clause for returning data, not a separate returning: option.","original_type":"feature"}
{"id":"el-xiy","title":"Implement Authorizer Hook for Row-Level Security","description":"Add support for authorizer hooks to enable row-level security and multi-tenant applications.\n\n**Context**: Authorizer hooks allow fine-grained access control at the SQL operation level. Essential for multi-tenant applications and row-level security (RLS).\n\n**Missing API** (from FEATURE_CHECKLIST.md):\n- authorizer() - Register callback that approves/denies SQL operations\n\n**Use Cases**:\n\n**1. Multi-Tenant Row-Level Security**:\n```elixir\n# Enforce tenant isolation at database level\nEctoLibSql.set_authorizer(repo, fn action, table, column, _context -\u003e\n  case action do\n    :read when table == \"users\" -\u003e\n      if current_tenant_can_read?(table) do\n        :ok\n      else\n        {:error, :unauthorized}\n      end\n    \n    :write when table in [\"users\", \"posts\"] -\u003e\n      if current_tenant_can_write?(table) do\n        :ok\n      else\n        {:error, :unauthorized}\n      end\n    \n    _ -\u003e :ok\n  end\nend)\n```\n\n**2. Column-Level Access Control**:\n```elixir\n# Restrict access to sensitive columns\nEctoLibSql.set_authorizer(repo, fn action, table, column, _context -\u003e\n  if column == \"ssn\" and !current_user_is_admin?() do\n    {:error, :forbidden}\n  else\n    :ok\n  end\nend)\n```\n\n**3. Audit Sensitive Operations**:\n```elixir\n# Log all DELETE operations\nEctoLibSql.set_authorizer(repo, fn action, table, _column, _context -\u003e\n  if action == :delete do\n    AuditLog.log_delete(current_user(), table)\n  end\n  :ok\nend)\n```\n\n**4. Prevent Dangerous Operations**:\n```elixir\n# Block DROP TABLE in production\nEctoLibSql.set_authorizer(repo, fn action, _table, _column, _context -\u003e\n  if action in [:drop_table, :drop_index] and production?() do\n    {:error, :forbidden}\n  else\n    :ok\n  end\nend)\n```\n\n**SQLite Authorizer Actions**:\n- :read - SELECT from table/column\n- :insert - INSERT into table\n- :update - UPDATE table/column\n- :delete - DELETE from table\n- :create_table, :drop_table\n- :create_index, :drop_index\n- :alter_table\n- :transaction\n- And many more...\n\n**Implementation Challenge**:\nSimilar to update_hook, requires Rust → Elixir callbacks with additional complexity:\n- Authorizer must return result synchronously (blocking)\n- Called very frequently (every SQL operation)\n- Performance critical (adds overhead to all queries)\n- Thread-safety for concurrent connections\n\n**Implementation Options**:\n\n**Option 1: Synchronous Callback (Required)**:\n- Authorizer MUST return result synchronously\n- Block Rust thread while waiting for Elixir\n- Use message passing with timeout\n- Handle timeout as :deny\n\n**Option 2: Pre-Compiled Rules (Performance)**:\n- Instead of arbitrary Elixir callback\n- Define rules in config\n- Compile to Rust decision tree\n- Much faster but less flexible\n\n**Proposed Implementation (Hybrid)**:\n\n1. **Add NIF** (native/ecto_libsql/src/connection.rs):\n   ```rust\n   #[rustler::nif]\n   fn set_authorizer(conn_id: \u0026str, pid: Pid) -\u003e NifResult\u003cAtom\u003e {\n       // Store pid in connection metadata\n       // Register libsql authorizer\n       // On auth check: send sync message to pid, wait for response\n   }\n   \n   #[rustler::nif]\n   fn remove_authorizer(conn_id: \u0026str) -\u003e NifResult\u003cAtom\u003e\n   ```\n\n2. **Add Elixir wrapper** (lib/ecto_libsql/native.ex):\n   ```elixir\n   def set_authorizer(state, callback_fn) do\n     pid = spawn(fn -\u003e authorizer_loop(callback_fn) end)\n     set_authorizer_nif(state.conn_id, pid)\n   end\n   \n   defp authorizer_loop(callback_fn) do\n     receive do\n       {:authorize, from, action, table, column, context} -\u003e\n         result = callback_fn.(action, table, column, context)\n         send(from, {:auth_result, result})\n         authorizer_loop(callback_fn)\n     end\n   end\n   ```\n\n3. **Rust authorizer implementation**:\n   ```rust\n   fn authorizer_callback(action: i32, table: \u0026str, column: \u0026str) -\u003e i32 {\n       // Send message to Elixir pid\n       // Wait for response with timeout (100ms)\n       // Return SQLITE_OK or SQLITE_DENY\n       // On timeout: SQLITE_DENY (safe default)\n   }\n   ```\n\n**Performance Considerations**:\n- ⚠️ Adds ~1-5ms overhead per SQL operation\n- Critical for read-heavy workloads\n- Consider caching auth decisions\n- Consider pre-compiled rules for performance-critical paths\n\n**Files**:\n- native/ecto_libsql/src/connection.rs (authorizer implementation)\n- native/ecto_libsql/src/models.rs (store authorizer pid)\n- lib/ecto_libsql/native.ex (wrapper and authorizer process)\n- lib/ecto/adapters/libsql.ex (public API)\n- test/authorizer_test.exs (new tests)\n- AGENTS.md (update API docs)\n\n**Acceptance Criteria**:\n- [ ] set_authorizer() NIF implemented\n- [ ] remove_authorizer() NIF implemented\n- [ ] Authorizer can approve operations (return :ok)\n- [ ] Authorizer can deny operations (return {:error, reason})\n- [ ] Authorizer receives correct action types\n- [ ] Authorizer timeout doesn't crash VM\n- [ ] Performance overhead \u003c 5ms per operation\n- [ ] Comprehensive tests including error cases\n- [ ] Multi-tenant example in documentation\n\n**Test Requirements**:\n```elixir\ntest \"authorizer can block SELECT operations\" do\n  EctoLibSql.set_authorizer(repo, fn action, _table, _column, _context -\u003e\n    if action == :read do\n      {:error, :forbidden}\n    else\n      :ok\n    end\n  end)\n  \n  assert {:error, _} = Repo.query(\"SELECT * FROM users\")\nend\n\ntest \"authorizer allows approved operations\" do\n  EctoLibSql.set_authorizer(repo, fn _action, _table, _column, _context -\u003e\n    :ok\n  end)\n  \n  assert {:ok, _} = Repo.query(\"SELECT * FROM users\")\nend\n\ntest \"authorizer timeout defaults to deny\" do\n  EctoLibSql.set_authorizer(repo, fn _action, _table, _column, _context -\u003e\n    Process.sleep(200)  # Timeout is 100ms\n    :ok\n  end)\n  \n  assert {:error, _} = Repo.query(\"SELECT * FROM users\")\nend\n```\n\n**References**:\n- FEATURE_CHECKLIST.md section \"Medium Priority\" item 5\n- LIBSQL_FEATURE_MATRIX_FINAL.md section 10\n- libsql API: conn.authorizer()\n- SQLite authorizer docs: https://www.sqlite.org/c3ref/set_authorizer.html\n\n**Dependencies**:\n- Similar to update_hook implementation\n- Can share callback infrastructure\n\n**Priority**: P2 - Enables advanced security patterns\n**Effort**: 5-7 days (complex synchronous Rust→Elixir callback)\n**Complexity**: High (performance-critical, blocking callbacks)\n**Security**: Critical - must handle timeouts safely","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:45:14.12598+11:00","created_by":"drew","updated_at":"2026-01-08T14:13:19.316204+11:00","closed_at":"2026-01-08T14:13:19.316211+11:00"}
{"id":"el-xkc","title":"Implement Update Hook for Change Data Capture","description":"Add support for update hooks to enable change data capture and real-time notifications.\n\n**Context**: Update hooks allow applications to receive notifications when database rows are modified. Critical for real-time updates, cache invalidation, and event sourcing patterns.\n\n**Missing API** (from FEATURE_CHECKLIST.md):\n- add_update_hook() - Register callback for INSERT/UPDATE/DELETE operations\n\n**Use Cases**:\n\n**1. Real-Time Updates**:\n```elixir\n# Broadcast changes via Phoenix PubSub\nEctoLibSql.set_update_hook(repo, fn action, _db, table, rowid -\u003e\n  Phoenix.PubSub.broadcast(MyApp.PubSub, \"table:\\#{table}\", {action, rowid})\nend)\n```\n\n**2. Cache Invalidation**:\n```elixir\n# Invalidate cache on changes\nEctoLibSql.set_update_hook(repo, fn _action, _db, table, rowid -\u003e\n  Cache.delete(\"table:\\#{table}:row:\\#{rowid}\")\nend)\n```\n\n**3. Audit Logging**:\n```elixir\n# Log all changes for compliance\nEctoLibSql.set_update_hook(repo, fn action, db, table, rowid -\u003e\n  AuditLog.insert(%{action: action, db: db, table: table, rowid: rowid})\nend)\n```\n\n**4. Event Sourcing**:\n```elixir\n# Append to event stream\nEctoLibSql.set_update_hook(repo, fn action, _db, table, rowid -\u003e\n  EventStore.append(table, %{type: action, rowid: rowid})\nend)\n```\n\n**Implementation Challenge**: \nCallbacks from Rust → Elixir are complex with NIFs. Requires:\n1. Register Elixir pid/function reference in Rust\n2. Send messages from Rust to Elixir process\n3. Handle callback results back in Rust (if needed)\n4. Thread-safety considerations for concurrent connections\n\n**Implementation Options**:\n\n**Option 1: Message Passing (Recommended)**:\n- Store Elixir pid in connection registry\n- Send messages to pid when updates occur\n- Elixir process handles messages asynchronously\n- No blocking in Rust code\n\n**Option 2: Synchronous Callback**:\n- Store function reference in registry\n- Call Elixir function from Rust\n- Wait for result (blocking)\n- More complex, potential deadlocks\n\n**Proposed Implementation (Option 1)**:\n\n1. **Add NIF** (native/ecto_libsql/src/connection.rs):\n   ```rust\n   #[rustler::nif]\n   fn set_update_hook(conn_id: \u0026str, pid: Pid) -\u003e NifResult\u003cAtom\u003e {\n       // Store pid in connection metadata\n       // Register libsql update hook\n       // On update: send message to pid\n   }\n   \n   #[rustler::nif]\n   fn remove_update_hook(conn_id: \u0026str) -\u003e NifResult\u003cAtom\u003e\n   ```\n\n2. **Add Elixir wrapper** (lib/ecto_libsql/native.ex):\n   ```elixir\n   def set_update_hook(state, callback_fn) do\n     pid = spawn(fn -\u003e update_hook_loop(callback_fn) end)\n     set_update_hook_nif(state.conn_id, pid)\n   end\n   \n   defp update_hook_loop(callback_fn) do\n     receive do\n       {:update, action, db, table, rowid} -\u003e\n         callback_fn.(action, db, table, rowid)\n         update_hook_loop(callback_fn)\n     end\n   end\n   ```\n\n3. **Update connection lifecycle**:\n   - Clean up hook process on connection close\n   - Handle hook process crashes gracefully\n   - Monitor hook process\n\n**Files**:\n- native/ecto_libsql/src/connection.rs (hook implementation)\n- native/ecto_libsql/src/models.rs (store hook pid in LibSQLConn)\n- lib/ecto_libsql/native.ex (wrapper and hook process)\n- lib/ecto/adapters/libsql.ex (public API)\n- test/update_hook_test.exs (new tests)\n- AGENTS.md (update API docs)\n\n**Acceptance Criteria**:\n- [ ] set_update_hook() NIF implemented\n- [ ] remove_update_hook() NIF implemented\n- [ ] Hook receives INSERT notifications\n- [ ] Hook receives UPDATE notifications\n- [ ] Hook receives DELETE notifications\n- [ ] Hook process cleaned up on connection close\n- [ ] Hook errors don't crash BEAM VM\n- [ ] Comprehensive tests including error cases\n- [ ] Documentation with examples\n\n**Test Requirements**:\n```elixir\ntest \"update hook receives INSERT notifications\" do\n  ref = make_ref()\n  EctoLibSql.set_update_hook(repo, fn action, db, table, rowid -\u003e\n    send(self(), {ref, action, db, table, rowid})\n  end)\n  \n  Repo.query(\"INSERT INTO users (name) VALUES ('Alice')\")\n  \n  assert_receive {^ref, :insert, \"main\", \"users\", rowid}\nend\n\ntest \"update hook doesn't crash VM on callback error\" do\n  EctoLibSql.set_update_hook(repo, fn _, _, _, _ -\u003e\n    raise \"callback error\"\n  end)\n  \n  # Should not crash\n  Repo.query(\"INSERT INTO users (name) VALUES ('Alice')\")\nend\n```\n\n**References**:\n- FEATURE_CHECKLIST.md section \"Medium Priority\" item 6\n- LIBSQL_FEATURE_MATRIX_FINAL.md section 10\n- libsql API: conn.update_hook()\n\n**Dependencies**:\n- None (can implement independently)\n\n**Priority**: P2 - Enables real-time and event-driven patterns\n**Effort**: 5-7 days (complex Rust→Elixir callback mechanism)\n**Complexity**: High (requires careful thread-safety design)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:44:39.628+11:00","created_by":"drew","updated_at":"2026-01-08T14:12:14.546185+11:00","closed_at":"2026-01-08T14:12:14.546188+11:00"}
{"id":"el-yr6","title":"Strengthen security test validation","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T14:16:50.897859+11:00","created_by":"drew","updated_at":"2026-01-12T11:57:52.242388+11:00","closed_at":"2026-01-12T11:57:52.242388+11:00","close_reason":"Security tests exist in test/security_test.exs (627 lines, 12 tests) with comprehensive validation of isolation boundaries","labels":["security","testing","tests"],"original_type":"task"}
{"id":"el-z8d","title":"File","description":"TESTING.md (create or update)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.021533+11:00","updated_at":"2026-01-12T11:58:16.857869+11:00","closed_at":"2026-01-12T11:58:16.857869+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
{"id":"el-z8u","title":"STRICT Tables (Type Enforcement)","description":"Not supported in migrations. SQLite 3.37+ (2021), libSQL 3.45.1 fully supports STRICT tables. Allowed types: INT, INTEGER, BLOB, TEXT, REAL. Rejects NULL types, unrecognised types, and generic types like TEXT(50) or DATE.\n\nDesired API:\n  create table(:users, strict: true) do\n    add :id, :integer, primary_key: true\n    add :name, :string  # Now MUST be text, not integer!\n  end\n\nPRIORITY: Recommended as #5 in implementation order.\n\nEffort: 2-3 days.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:35:51.561346+11:00","created_by":"drew","updated_at":"2026-01-05T14:41:53.948931+11:00","close_reason":"Implemented STRICT Tables support in migrations. Tables now support strict: true option to enforce column type safety. Documentation added to AGENTS.md covering benefits, allowed types, usage examples, and error handling.","original_type":"feature"}
{"id":"el-zba","title":"Impact","description":"Track performance across versions, validate improvements, identify bottlenecks","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T21:34:13.02081+11:00","updated_at":"2026-01-12T11:58:16.860843+11:00","closed_at":"2026-01-12T11:58:16.860843+11:00","close_reason":"Malformed fragment issue - not a valid task","original_type":"task"}
